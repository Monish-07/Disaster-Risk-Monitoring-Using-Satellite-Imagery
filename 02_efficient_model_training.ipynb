{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f36efa-b9f8-4935-a403-a4010cdbad8e",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/combined_logo.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ee592-705e-49c5-a26c-dd7cacfbb545",
   "metadata": {},
   "source": [
    "# Disaster Risk Monitoring Using Satellite Imagery #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a48909-8799-4b25-bd11-91cc92fb46a1",
   "metadata": {},
   "source": [
    "## 02 - Efficient Model Training ##\n",
    "In this notebook, you will learn how to train a segmentation model with the TAO Toolkit using pre-trained ResNet-18 weights. In addition, you will learn how to export the model for deployment. \n",
    "\n",
    "**Table of Contents**\n",
    "<br>\n",
    "This notebook covers the below sections: \n",
    "1. [Introduction to the TAO Toolkit](#s2-1)\n",
    "    * [Transfer Learning](#s2-1.1)\n",
    "    * [Vision AI Pre-Trained Models Supported](#s2-1.2)\n",
    "    * [TAO Toolkit Workflow](#s2-1.3)\n",
    "    * [TAO Launcher, CLI (Command Line Interface), and Spec Files](#s2-1.4)\n",
    "    * [Set Up Environment Variables](#s2-1.5)\n",
    "    * [Exercise #1 - Explore TAO Toolkit CLI](#s2-e1)\n",
    "2. [U-Net Semantic Segmentation Model](#s2-2)\n",
    "    * [Preparation for Model Training](#s2-2.1)\n",
    "    * [Download Pre-Trained Model](#s2-2.2)\n",
    "    * [Prepare Dataset](#s2-2.3)\n",
    "    * [Model Training](#s2-2.4)\n",
    "    * [Exercise #2 - Modify Dataset Config](#s2-e2)\n",
    "    * [Exercise #3 - Modify Model Config](#s2-e3)\n",
    "    * [Exercise #4 - Modify Training Config](#s2-e4)\n",
    "    * [Combine Configuration Files](#s2-2.5)\n",
    "    * [Initiate Model Training](#s2-2.6)\n",
    "    * [Evaluating the Model](#s2-2.7)\n",
    "    * [Visualizing Model Inference](#s2-2.8)\n",
    "3. [Model Export](#s2-3)\n",
    "    * [TensorRT - Programmable Inference Accelerator](#s2-3.1)\n",
    "    * [Export the Trained Model](#s2-3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ae3a29-df70-4396-a6f4-d1d8d164d5ff",
   "metadata": {},
   "source": [
    "<a name='s2-1'></a>\n",
    "## Introduction to the TAO Toolkit ##\n",
    "The TAO Toolkit, Train Adapt Optimize, is a framework that simplifies the AI/ML model development workflow. It lets developers fine-tune pre-trained models with custom data to produce highly accurate computer vision models efficiently, eliminating the need for large training runs and deep AI expertise. In addition, it also enables model optimization for inference performance. You can learn more about the TAO Toolkit [here](https://developer.nvidia.com/tao-toolkit) or read the documentation [here](https://docs.nvidia.com/tao/tao-toolkit/index.html#).\n",
    "<p><img src=\"images/tao_toolkit.png\" width=720></p>\n",
    "\n",
    "The TAO Toolkit uses pre-trained models to accelerate the AI development process and reduce costs associated with large scale data collection, labeling, and training models from scratch. Transfer learning with pre-trained models can be used for classification, object detection, and image segmentation tasks. The TAO Toolkit offers useful features such as:\n",
    "* Low-coding approach that requires no AI framework expertise, reducing the barrier of entry for anyone who wants to get started building AI-based applications\n",
    "* Flexible configurations that allow customization to help advance users prototype faster\n",
    "* Large catalogue of production-ready pre-trained models for common Computer Vision (CV) tasks that can also be customized with users' own data\n",
    "* Easy to use interface for model optimization such as pruning and quantization-aware training\n",
    "* Integration with the Triton Inference Server\n",
    "\n",
    "_Note: The TAO Toolkit comes with a set of reference scripts and configuration specifications with default parameter values that enable developers to kick-start training and fine-tuning. This lowers the bar and enables users without a deep understanding of models, expertise in deep learning, or beginning coding skills to be able to train new models and fine-tune the pre-trained ones._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8aca25-bc7a-4dc7-a4d3-b903cbdf13f4",
   "metadata": {},
   "source": [
    "<a name='s2-1.1'></a>\n",
    "### Transfer Learning ###\n",
    "In practice, it is rare and inefficient to initiate the learning task on a network with randomly initialized weights due to factors like data scarcity (inadequate number of training samples) or prolonged training times. One of the most common techniques to overcome this is to use transfer learning. Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where developers use a model trained on one task and re-train to use it on a different task. This works surprisingly well as many of the early layers in a neural network are the same for similar tasks. For example, many of the early layers in a convolutional neural network used for a CV model are primarily used to identify outlines, curves, and other features in an image. The network formed by these layers are referred to as the **backbone** of a more complex model. Also known as feature extractors, they take as input the image and extracts the feature map upon which the rest of the network is based. The learned features from these layers can be applied to similar tasks carrying out the same identification in other domains. Transfer learning enables adaptation (fine-tuning) of an existing neural network to a new one, which requires significantly less domain-specific data. In most cases, fine-tuning takes significantly less time (a reduction by x10 factor is common), saving time and resources. As it relates to vision AI, transfer learning can be used for adding new classification by transferring weights from one application to another.\n",
    "\n",
    "<p><img src='images/transfer_learning.png' width=720></p>\n",
    "\n",
    "More information about transfer learning can be found in this [blog](https://blogs.nvidia.com/blog/2019/02/07/what-is-transfer-learning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb01061-8a05-4c4f-96aa-28926278b503",
   "metadata": {},
   "source": [
    "<a name='s2-1.2'></a>\n",
    "### Vision AI Pre-Trained Models Supported ###\n",
    "Developers, system builders, and software partners building disaster risk monitoring systems can bring their own custom data to train with and fine-tune pre-trained models quickly instead of going through significant effort in large data collection and training from scratch. **General purpose vision models** provide pre-trained weights for popular network architectures to train an image classification model, an object detection model, or a segmentation model. This gives users the flexibility and control to build AI models for any number of applications, from smaller lightweight models for edge deployment to larger models for more complex tasks. They are trained on the [Open Images](https://opensource.google/projects/open-images-dataset) dataset and provide a much better starting point for training versus training from scratch or starting from random weights. \n",
    "\n",
    "The TAO Toolkit adapts popular network architectures and backbones to custom data, allowing developers to train, fine tune, prune, and export highly optimized and accurate AI models. When working with TAO, first choose the model architecture to be built, then choose one of the supported backbones. \n",
    "<p><img src='images/openimage_table.jpg' width=720></p>\n",
    "\n",
    "_Note: The pre-trained weights from each feature extraction network merely act as a starting point and may not be used without re-training. In addition, the pre-trained weights are network specific and shouldn't be shared across models that use different architectures._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319ca49-760b-4aa1-b2f5-8c31657c125c",
   "metadata": {},
   "source": [
    "<a name='s2-1.3'></a>\n",
    "### TAO Toolkit Workflow ###\n",
    "Building disaster risk monitoring systems is hard, and tailoring even a single component to the needs of the enterprise for deployment is even harder. Deployment for a domain-specific application typically requires several cycles of re-training, fine-tuning, and deploying the model until it satisfies the requirements. As a starting point, training typically follows the below steps: \n",
    "\n",
    "0. Configuration\n",
    "1. Download a pre-trained model from NGC\n",
    "2. Prepare the data for training\n",
    "3. Train the model using transfer learning\n",
    "4. Evaluate the model for target predictions\n",
    "5. Export the model\n",
    "* Steps to optimize the model for improved inference performance\n",
    "\n",
    "<p><img src='images/tao_toolkit_workflow.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb69288-90df-455f-b53a-0a32adf74dbc",
   "metadata": {},
   "source": [
    "<a name='s2-1.4'></a>\n",
    "### TAO Launcher, CLI (Command Line Interface), and Spec Files ###\n",
    "The TAO Toolkit is a low-coding framework that makes it easy to get started. It uses a **launcher** to pull from NGC registry and instantiate the appropriate TAO [container](https://www.docker.com/resources/what-container/) that performs the desired subtasks such as convert data, train, evaluate, or export. The TAO launcher is a python package distributed as a python wheel listed in the `nvidia-pyindex` python index, which has been prepared for you already. \n",
    "\n",
    "Users interact with the launcher with its **Command Line Interface** that is configured using simple [**Protocol Buffer**](https://developers.google.com/protocol-buffers) **specification files** to include parameters such as the dataset parameters, model parameters, and optimizer and training hyperparameters. More information about the TAO Toolkit Launcher can be found in the [TAO Docs](https://docs.nvidia.com/tao/tao-toolkit/text/tao_launcher.html#tao-launcher). \n",
    "\n",
    "The tasks can be invoked from the TAO Toolkit Launcher using the convention `tao <task> <subtask> <args_per_subtask>`, where `<args_per_subtask>` are the arguments required for a given subtask. Once the container is launched, the subtasks are run by the TAO Toolkit containers using the appropriate hardware resources. \n",
    "<p><img src='images/tao_launcher.gif' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f316b3-e7b5-4a3a-8cc8-8f6c8f6f00a0",
   "metadata": {},
   "source": [
    "<p><img src='images/important.png' width=720></p>\n",
    "Since the TAO Toolkit uses the launcher to pull containers, the first time running a task may take extra time to load."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7f4ec-1826-499f-b001-28d1eb0d71a1",
   "metadata": {},
   "source": [
    "<a name='s2-1.5'></a>\n",
    "### Set Up Environment Variables ###\n",
    "We set up a couple of environment variables to help us mount the local directories to the tao container. Specifically, we want to set paths for the `$LOCAL_TRAINING_DATA`, `$LOCAL_SPEC_DIR`, and `$LOCAL_PROJECT_DIR` for the output of the TAO experiment with their respective paths in the TAO container. In doing so, we can make sure that the TAO experiment generated collaterals such as checkpoints, model files (e.g. `.tlt` or `.etlt`), and logs are output to `$LOCAL_PROJECT_DIR/unet`. \n",
    "\n",
    "_Note that users will be able to define their own export encryption key when training from a general-purpose model. This is to protect proprietary IP and used to decrypt the `.etlt` model during deployment._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446943db-e633-4b5b-9997-c767a849085d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KEY=my_model_key\n",
      "env: LOCAL_PROJECT_DIR=/dli/task/tao_project\n",
      "env: LOCAL_DATA_DIR=/dli/task/flood_data\n",
      "env: LOCAL_SPECS_DIR=/dli/task/tao_project/spec_files\n",
      "env: TAO_PROJECT_DIR=/workspace/tao-experiments\n",
      "env: TAO_DATA_DIR=/workspace/tao-experiments/data\n",
      "env: TAO_SPECS_DIR=/workspace/tao-experiments/spec_files\n",
      "env: TAO_EXPERIMENT_DIR=/workspace/tao-experiments/unet\n",
      "mkdir: cannot create directory ‘/dli/task/tao_project/unet’: File exists\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# set environment variables\n",
    "import os\n",
    "import json\n",
    "\n",
    "%set_env KEY=my_model_key\n",
    "\n",
    "%set_env LOCAL_PROJECT_DIR=/dli/task/tao_project\n",
    "%set_env LOCAL_DATA_DIR=/dli/task/flood_data\n",
    "%set_env LOCAL_SPECS_DIR=/dli/task/tao_project/spec_files\n",
    "os.environ[\"LOCAL_EXPERIMENT_DIR\"]=os.path.join(os.getenv(\"LOCAL_PROJECT_DIR\"), \"unet\")\n",
    "\n",
    "%set_env TAO_PROJECT_DIR=/workspace/tao-experiments\n",
    "%set_env TAO_DATA_DIR=/workspace/tao-experiments/data\n",
    "%set_env TAO_SPECS_DIR=/workspace/tao-experiments/spec_files\n",
    "%set_env TAO_EXPERIMENT_DIR=/workspace/tao-experiments/unet\n",
    "\n",
    "!mkdir $LOCAL_EXPERIMENT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe38326-8dc7-438f-b392-913166d3a185",
   "metadata": {},
   "source": [
    "The cell below maps the project directory on your local host to a workspace directory in the TAO docker instance, so that the data and the results are mapped from in and out of the docker. This is done by creating a `.tao_mounts.json` file. For more information, please refer to the [launcher instance](https://docs.nvidia.com/tao/tao-toolkit/tao_launcher.html) in the user guide. Setting the `DockerOptions` ensures that you don't have permission issues when writing data into folders created by the TAO docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a30e1d-a66d-4752-85d7-6676f31c3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# mapping up the local directories to the TAO docker\n",
    "mounts_file = os.path.expanduser(\"~/.tao_mounts.json\")\n",
    "\n",
    "drive_map = {\n",
    "    \"Mounts\": [\n",
    "            # Mapping the data directory\n",
    "            {\n",
    "                \"source\": os.environ[\"LOCAL_PROJECT_DIR\"],\n",
    "                \"destination\": \"/workspace/tao-experiments\"\n",
    "            },\n",
    "            # Mapping the specs directory.\n",
    "            {\n",
    "                \"source\": os.environ[\"LOCAL_SPECS_DIR\"],\n",
    "                \"destination\": os.environ[\"TAO_SPECS_DIR\"]\n",
    "            },\n",
    "            # Mapping the data directory.\n",
    "            {\n",
    "                \"source\": os.environ[\"LOCAL_DATA_DIR\"],\n",
    "                \"destination\": os.environ[\"TAO_DATA_DIR\"]\n",
    "            },\n",
    "        ],\n",
    "    \"DockerOptions\": {\n",
    "        \"user\": \"{}:{}\".format(os.getuid(), os.getgid())\n",
    "    }\n",
    "}\n",
    "\n",
    "# writing the mounts file\n",
    "with open(mounts_file, \"w\") as mfile:\n",
    "    json.dump(drive_map, mfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f9528-4a82-4e03-8719-55b30ff8e546",
   "metadata": {},
   "source": [
    "To see the usage of different functionality that are supported, use the `-h` or `--help` option. For more information, see the [TAO Toolkit Quick Start Guide](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_quick_start_guide.html). \n",
    "Here is the **sample output**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2c2ed9-6c06-4e74-aa9e-1dc3034228c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tao [-h]\n",
      "           {list,stop,info,action_recognition,augment,bpnet,classification,converter,detectnet_v2,dssd,efficientdet,emotionnet,faster_rcnn,fpenet,gazenet,gesturenet,heartratenet,intent_slot_classification,lprnet,mask_rcnn,multitask_classification,n_gram,punctuation_and_capitalization,question_answering,retinanet,spectro_gen,speech_to_text,speech_to_text_citrinet,ssd,text_classification,token_classification,unet,vocoder,yolo_v3,yolo_v4,yolo_v4_tiny}\n",
      "           ...\n",
      "\n",
      "Launcher for TAO Toolkit.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "tasks:\n",
      "  {list,stop,info,action_recognition,augment,bpnet,classification,converter,detectnet_v2,dssd,efficientdet,emotionnet,faster_rcnn,fpenet,gazenet,gesturenet,heartratenet,intent_slot_classification,lprnet,mask_rcnn,multitask_classification,n_gram,punctuation_and_capitalization,question_answering,retinanet,spectro_gen,speech_to_text,speech_to_text_citrinet,ssd,text_classification,token_classification,unet,vocoder,yolo_v3,yolo_v4,yolo_v4_tiny}\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "!tao --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24d50a-f760-483c-90e0-680a45869b26",
   "metadata": {},
   "source": [
    "With the TAO Toolkit, users can train models for object detection, classification, segmentation, optical character recognition, facial landmark estimation, gaze estimation, and more. In TAO's terminology, these would be the **tasks**, which support **subtasks** such as `train`, `prune`, `evaluate`, `export`, etc. Each task/subtask requires different combinations of configuration files to accommodate for different parameters, such as the dataset parameters, model parameters, and optimizer and training hyperparameters. Part of what makes TAO Toolkit so easy to use is that most of those parameters are hidden away in the form of experiment specification files (spec files). They are detailed in the [documentation](https://docs.nvidia.com/tao/tao-toolkit/#tao-toolkit) for reference. It's very helpful to have these resources handy when working with the TAO Toolkit. In addition, there are several specific tasks that help with handling the launched commands. \n",
    "\n",
    "Below are the tasks available in the TAO Toolkit, organized by their respective computer vision objectives. We grayed out the tasks for Conversational AI as they are out of scope for this course.\n",
    "\n",
    "<img src='images/tao_tasks.png' width=740>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81e20c-14fa-4b8f-a630-ed8d9a509b59",
   "metadata": {},
   "source": [
    "<a name='s2-e1'></a>\n",
    "### Exercise #1 - Explore TAO Toolkit CLI ###\n",
    "Let's explore some TAO Toolkit tasks. \n",
    "\n",
    "**Instructions**:<br>\n",
    "* Modify the `<FIXME>`s only and execute the cell, choosing a task from options such as: `[classification, detectnet_v2, mask_rcnn, emotionnet, etc.]`, followed by a subtask from options such as: `[calibration_tensorfile, dataset_convert, evaluate, export, inference, prune, train]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6698ea-f544-417e-9f19-9f205b473e55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 10:00:22,917 [INFO] root: Registry: ['nvcr.io']\n",
      "2023-10-09 10:00:23,062 [INFO] tlt.components.instance_handler.local_instance: Running command in container: nvcr.io/nvidia/tao/tao-toolkit-tf:v3.21.11-tf1.15.5-py3\n",
      "2023-10-09 10:00:23,063 [INFO] tlt.components.docker_handler.docker_handler: The required docker doesn't exist locally/the manifest has changed. Pulling a new docker.\n",
      "2023-10-09 10:00:23,064 [INFO] tlt.components.docker_handler.docker_handler: Pulling the required container. This may take several minutes if you're doing this for the first time. Please wait here.\n",
      "...\n",
      "Pulling from repository: nvcr.io/nvidia/tao/tao-toolkit-tf\n",
      "2023-10-09 10:08:27,732 [INFO] tlt.components.docker_handler.docker_handler: Container pull complete.\n",
      "Using TensorFlow backend.\n",
      "usage: unet train [-h] [--num_processes NUM_PROCESSES] [--gpus GPUS]\n",
      "                  [--gpu_index GPU_INDEX [GPU_INDEX ...]] [--use_amp]\n",
      "                  [--log_file LOG_FILE] [-e EXPERIMENT_SPEC_FILE]\n",
      "                  [-m PRETRAINED_MODEL_FILE] [-r RESULTS_DIR] [-n MODEL_NAME]\n",
      "                  [-v] -k KEY\n",
      "                  {evaluate,export,inference,prune,train} ...\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --num_processes NUM_PROCESSES, -np NUM_PROCESSES\n",
      "                        The number of horovod child processes to be spawned.\n",
      "                        Default is -1(equal to --gpus).\n",
      "  --gpus GPUS           The number of GPUs to be used for the job.\n",
      "  --gpu_index GPU_INDEX [GPU_INDEX ...]\n",
      "                        The indices of the GPU's to be used.\n",
      "  --use_amp             Flag to enable Auto Mixed Precision.\n",
      "  --log_file LOG_FILE   Path to the output log file.\n",
      "  -e EXPERIMENT_SPEC_FILE, --experiment_spec_file EXPERIMENT_SPEC_FILE\n",
      "                        Path to spec file. Absolute path or relative to\n",
      "                        working directory. If not specified, default spec from\n",
      "                        spec_loader.py is used.\n",
      "  -m PRETRAINED_MODEL_FILE, --pretrained_model_file PRETRAINED_MODEL_FILE\n",
      "                        Model path to the pre-trained weights.\n",
      "  -r RESULTS_DIR, --results_dir RESULTS_DIR\n",
      "                        Path to a folder where experiment outputs should be\n",
      "                        written.\n",
      "  -n MODEL_NAME, --model_name MODEL_NAME\n",
      "                        Name of the model file. If not given, then defaults to\n",
      "                        model.tlt.\n",
      "  -v, --verbose         Set verbosity level for the logger.\n",
      "  -k KEY, --key KEY     The key to load pretrained weights and save\n",
      "                        intermediate snapshopts and final model.\n",
      "\n",
      "tasks:\n",
      "  {evaluate,export,inference,prune,train}\n",
      "2023-10-09 10:08:34,129 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# Example: !tao unet train --help\n",
    "!tao unet train --help"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bac54013-b78f-4c84-9753-b409e9b019d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "!tao unet train --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf953065-06a7-491f-9fef-f5c2c24f7f8b",
   "metadata": {},
   "source": [
    "Click ... to show **solution**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f19dad-30cb-4d12-a15d-7268743ab2b3",
   "metadata": {},
   "source": [
    "<p><img src='images/check.png' width=720></p>\n",
    "\n",
    "Did you get the below error message? This is likely due to a bad NGC configuration. Please check the NGC CLI and Docker Registry section of the [introduction notebook](00_introduction.ipynb)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff968ed5-77ee-4237-8709-f55e96cc70b0",
   "metadata": {},
   "source": [
    "AssertionError: Config path must be a valid unix path. No file found at: /root/.docker/config.json. Did you run docker login?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f932728-0ae0-40bf-82b7-32f7b935cf8d",
   "metadata": {},
   "source": [
    "<a name='s2-2'></a>\n",
    "## U-Net Semantic Segmentation Model ##\n",
    "[U-Net](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/pretrained_semantic_segmentation) is a neural network for image segmentation. This is the type of task we want to perform for our disaster risk monitoring system in order to label each pixel as either `flood` or `notflood`. With the TAO Toolkit, we can choose the desired ResNet-18 backbone as a feature extractor. As such, we will use the `unet` task, which supports the following subtasks: \n",
    "* `train`\n",
    "* `evaluate`\n",
    "* `inference`\n",
    "* `prune`\n",
    "* `export`\n",
    "\n",
    "<p><img src='images/rewind.png' width=720><p>\n",
    "    \n",
    "These subtasks can be invoked using the convention `tao unet <subtask> <args_per_subtask>` on the command-line, where `args_per_subtask` are the arguments required for a given subtask. Additionally, we can always find more information about these subtasks with `tao unet <subtask> -h` or `tao unet <subtask> --help`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281849b7-b93b-4d41-9437-8e34a2953087",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s2-2.1'></a>\n",
    "### Preparation for Model Training ###\n",
    "For the remaining of the notebook, we will use the TAO Toolkit to train a semantic segmentation model. Below is what the model development workflow looks like. We start by preparing a pre-trained model and the data. Next, we prepare the configuration file(s) and begin to train the model with new data and evaluate its performance. We will export the model once its satisfactory. Note that this notebook does not include inference optimization steps, which is important for disaster risk monitoring systems that are deployed on edge devices. \n",
    "<p><img src='images/simple_workflow.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0bde40-85ba-472c-9984-6222fbf4d3d9",
   "metadata": {},
   "source": [
    "<a name='s2-2.2'></a>\n",
    "### Download Pre-Trained Model ###\n",
    "Developers typically begin by choosing and downloading a pre-trained model from [NGC](https://ngc.nvidia.com/), which contains pre-trained weights of the architecture of their choice. It's difficult to immediately identify which model/architecture will work best for a specific use case as there is often a tradeoff between time to train, accuracy, and inference performance. It is common to compare across multiple models before picking the best candidate.\n",
    "\n",
    "Here are some pointers that will help choose an appropriate model: \n",
    "* Look at the model inputs/outputs to decide if it will fit your use case. \n",
    "* Input format is also an important consideration. For example, some models expect the input to be 0-1 normalized with input channels in RGB order. Some models that use a different input order may require input preprocessing/mean subtraction that might result in suboptimal performance. \n",
    "\n",
    "We can use the `ngc registry model list <model_glob_string>` command to get a list of models that are hosted on the NGC model registry. For example, we can use `ngc registry model list nvidia/tao/*` to list all available models. The `--column` option identifies the columns of interest. More information about the NGC Registry CLI can be found in the [User Guide](https://docs.nvidia.com/dgx/pdf/ngc-registry-cli-user-guide.pdf). `The ngc registry model download-version <org>/[<team>/]<model-name:version>` command will download the model from the registry. It has a `--dest` option to specify the path to download directory. Alternatively, a catalog of support models can also be found [here](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/collections/tao_computervision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6a84c4-b633-41d1-a34d-7cd70282f348",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"accuracyReached\": 77.56,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:43:25.180Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"153.7169\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 161183816,\n",
      "    \"versionId\": \"vgg19\"\n",
      "},{\n",
      "    \"accuracyReached\": 82.2,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:43:56.685Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"515.0932\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 540114376,\n",
      "    \"versionId\": \"vgg16\"\n",
      "},{\n",
      "    \"accuracyReached\": 77.91,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:44:52.409Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"294.1976\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 308488496,\n",
      "    \"versionId\": \"resnet50\"\n",
      "},{\n",
      "    \"accuracyReached\": 77.04,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:45:22.007Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"170.6549\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 178944632,\n",
      "    \"versionId\": \"resnet34\"\n",
      "},{\n",
      "    \"accuracyReached\": 76.74,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:45:42.209Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"88.9573\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 93278448,\n",
      "    \"versionId\": \"resnet18\"\n",
      "},{\n",
      "    \"accuracyReached\": 77.78,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:45:54.627Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"576.3329\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 604328880,\n",
      "    \"versionId\": \"resnet101\"\n",
      "},{\n",
      "    \"accuracyReached\": 74.38,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:47:01.252Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"38.3121\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 40173128,\n",
      "    \"versionId\": \"resnet10\"\n",
      "},{\n",
      "    \"accuracyReached\": 77.11,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:47:19.420Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"16.9008\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 17721744,\n",
      "    \"versionId\": \"efficientnet_b0_swish\"\n",
      "},{\n",
      "    \"accuracyReached\": 77.11,\n",
      "    \"batchSize\": 1,\n",
      "    \"createdByUser\": \"n90fe0en2gvll5957fel7u75sg\",\n",
      "    \"createdDate\": \"2021-08-24T13:47:35.558Z\",\n",
      "    \"description\": \"\",\n",
      "    \"gpuModel\": \"V100\",\n",
      "    \"memoryFootprint\": \"16.9008\",\n",
      "    \"numberOfEpochs\": 80,\n",
      "    \"status\": \"UPLOAD_COMPLETE\",\n",
      "    \"totalFileCount\": 1,\n",
      "    \"totalSizeInBytes\": 17721744,\n",
      "    \"versionId\": \"efficientnet_b0_relu\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# list all available models\n",
    "!ngc registry model list nvidia/tao/pretrained_semantic_segmentation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334806b-5dd7-4c36-b1a4-b2bfe2620ffe",
   "metadata": {},
   "source": [
    "<p><img src='images/check.png' width=720></p>\n",
    "\n",
    "Did you get the below error message? This is likely due to a bad NGC CLI configuration. Please check the NGC CLI and Docker Registry section of the [introduction notebook](00_introduction.ipynb)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d0d9d37-d76a-420e-bfea-f1a05e902488",
   "metadata": {},
   "source": [
    "{\n",
    "    \"error\": \"Error: Invalid apikey\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffefc95-2e28-4d30-bcb1-64bc1a8fdf33",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"download_end\": \"2023-10-09 10:10:23.792583\",\n",
      "    \"download_start\": \"2023-10-09 10:10:16.784517\",\n",
      "    \"download_time\": \"7s\",\n",
      "    \"files_downloaded\": 1,\n",
      "    \"local_path\": \"/dli/task/tao_project/unet/pretrained_resnet18/pretrained_semantic_segmentation_vresnet18\",\n",
      "    \"size_downloaded\": \"82.38 MB\",\n",
      "    \"status\": \"Completed\",\n",
      "    \"transfer_id\": \"pretrained_semantic_segmentation_vresnet18\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# create directory to store the pre-trained model\n",
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/pretrained_resnet18/\n",
    "\n",
    "# download the pre-trained segmentation model from NGC\n",
    "!ngc registry model download-version nvidia/tao/pretrained_semantic_segmentation:resnet18 \\\n",
    "    --dest $LOCAL_EXPERIMENT_DIR/pretrained_resnet18 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac3ffc-7afb-4369-804f-7614b0f639fa",
   "metadata": {},
   "source": [
    "For this lab, we will use _ResNet18_ as the architecture for the semantic segmentation model. [Residual neural network](https://en.wikipedia.org/wiki/Residual_neural_network), or **ResNet**, is a type of convolutional neural network used as a backbone for many computer vision tasks. The `18` refers to the number of layers in this architecture. It should be noted that typically the deeper (i.e. more layers) a neural network is, the more time consuming it is to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b747f9d-8788-4c77-a6f6-b8d5440e503e",
   "metadata": {},
   "source": [
    "<p><img src='images/tip.png' width=720></p>\n",
    "\n",
    "We designated the model to be downloaded locally to `tao_project/unet/pretrained_resnet18`, which is mapped to `/workspace/tao-experiments/unet/pretrained_resnet18` in the TAO container based on the mapping of `LOCAL_PROJECT_DIR` to `TAO_PROJECT_DIR`. Looking at the `local_path` and `transfer_id` keys of the output JSON, we can gather that the path of the pre-trained model should be in the `tao_project/unet/pretrained_resnet18/pretrained_semantic_segmentation_vresnet18 directory`. When referencing paths for the TAO Toolkit, it's important to use paths based on the TAO container. In this case it would be `/workspace/tao-experiments/unet/pretrained_resnet18/pretrained_semantic_segmentation_vresnet18`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b667fe1-928b-48df-b1fb-dfc762661035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtao_project/unet/pretrained_resnet18\u001b[00m\n",
      "└── \u001b[01;34mpretrained_semantic_segmentation_vresnet18\u001b[00m\n",
      "    └── resnet_18.hdf5\n",
      "\n",
      "1 directory, 1 file\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "!tree -a tao_project/unet/pretrained_resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e1652-fe1f-4a17-9307-0d2353ab1945",
   "metadata": {},
   "source": [
    "<a name='s2-2.3'></a>\n",
    "### Prepare Dataset ###\n",
    "The TAO Toolkit expects the training data for the `unet` subtasks to be in the format described in the [documentation](https://docs.nvidia.com/tao/tao-toolkit/text/data_annotation_format.html#id8). Each mask image is a single-channel image, where every pixel is assigned an integer value that represents the segmentation class `label_id`, as per the mapping provided in the `dataset_config`. Additionally, each image and label have the same file ID before the extension and size. The image-to-label correspondence is maintained using this filename. The data folder structure for images and masks must be in the following format. \n",
    "<p><img src='images/semantic_segmentation_input.PNG' width=720></p>\n",
    "\n",
    "_The `test` folder in the above directory structure is optional; any folder can be used for inference._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89e3e5-08a5-4bda-95db-9697acf0694c",
   "metadata": {},
   "source": [
    "Below we will split the data into `train` set and `validation` set and copy the images into their respective folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9ebbf0-1e1b-470e-9c3b-7fd9fcc62906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# remove existing splits\n",
    "!rm -rf $LOCAL_DATA_DIR/images/train\n",
    "!mkdir -p $LOCAL_DATA_DIR/images/train\n",
    "!rm -rf $LOCAL_DATA_DIR/images/val\n",
    "!mkdir -p $LOCAL_DATA_DIR/images/val\n",
    "\n",
    "!rm -rf $LOCAL_DATA_DIR/masks/train\n",
    "!mkdir -p $LOCAL_DATA_DIR/masks/train\n",
    "!rm -rf $LOCAL_DATA_DIR/masks/val\n",
    "!mkdir -p $LOCAL_DATA_DIR/masks/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d3a078-58db-42a6-b873-56d87f024ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "from random import sample\n",
    "import shutil\n",
    "\n",
    "# define split ratio\n",
    "split=0.75\n",
    "\n",
    "# get all images\n",
    "file_list=os.listdir(f\"{os.environ['LOCAL_DATA_DIR']}/images/all_images\")\n",
    "image_count=len(file_list)\n",
    "train_image_list=sample(file_list, int(image_count*split))\n",
    "val_image_list=[file for file in file_list if file not in train_image_list]\n",
    "\n",
    "# move all training images to train directory\n",
    "for each_file in train_image_list: \n",
    "    if each_file.split('.')[-1]=='png': \n",
    "        shutil.copyfile(f\"{os.environ['LOCAL_DATA_DIR']}/images/all_images/{each_file}\", f\"{os.environ['LOCAL_DATA_DIR']}/images/train/{each_file}\")\n",
    "        shutil.copyfile(f\"{os.environ['LOCAL_DATA_DIR']}/masks/all_masks/{each_file}\", f\"{os.environ['LOCAL_DATA_DIR']}/masks/train/{each_file}\")\n",
    "\n",
    "# move all validation images to val directory\n",
    "for each_file in val_image_list: \n",
    "    if each_file.split('.')[-1]=='png': \n",
    "        shutil.copyfile(f\"{os.environ['LOCAL_DATA_DIR']}/images/all_images/{each_file}\", f\"{os.environ['LOCAL_DATA_DIR']}/images/val/{each_file}\")\n",
    "        shutil.copyfile(f\"{os.environ['LOCAL_DATA_DIR']}/masks/all_masks/{each_file}\", f\"{os.environ['LOCAL_DATA_DIR']}/masks/val/{each_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b710aa-c92c-4d09-934f-5096b2711965",
   "metadata": {},
   "source": [
    "<a name='s2-2.4'></a>\n",
    "### Model Training ###\n",
    "Training configuration is done through a training spec file, which includes options such as which dataset to use for training, which dataset to use for validation, which pre-trained model architecture to use, which hyperparameters to tune, and other training options. The `train`, `evaluate`, `prune`, and `inference` subtasks for a U-Net experiment share the same configuration file. Configuration files can be created from scratch or modified using the templates provided in TAO Toolkit's [sample applications](https://docs.nvidia.com/tao/tao-toolkit/#cv-applications). \n",
    "\n",
    "The training configuration file has the following sections: \n",
    "* `dataset_config`\n",
    "* `model_config`\n",
    "* `training_config`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb34518-d2fd-449c-bcbf-fa5b2fcd086f",
   "metadata": {},
   "source": [
    "<p><img src='images/important.png' width=720></p>\n",
    "We will create the configuration files using templates. Specifically, we have broken the configuration files into separate parts for ease of discussion, which we will combine at the end for the TAO Toolkit to consume. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4241d-14b2-44fb-8820-83c3d61f93cd",
   "metadata": {},
   "source": [
    "Execute the below cells to preview the combined training/evaluation configuration file that will be used. It is currently not usable as we have made some intentional modifications that will require correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a3201c-2443-4f94-852f-f15cc51b25e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_config {\n",
      "  dataset: \"<<<<FIXME>>>>\"\n",
      "  augment: <<<<FIXME>>>>\n",
      "  augmentation_config {\n",
      "    spatial_augmentation {\n",
      "      hflip_probability : 0.5\n",
      "      vflip_probability : 0.5\n",
      "      crop_and_resize_prob : 0.5\n",
      "    }\n",
      "  }\n",
      "  input_image_type: \"<<<<FIXME>>>>\"\n",
      "  train_images_path: \"/workspace/tao-experiments/data/<<<<FIXME>>>>\"\n",
      "  train_masks_path: \"/workspace/tao-experiments/data/<<<<FIXME>>>>\"\n",
      "\n",
      "  val_images_path: \"/workspace/tao-experiments/data/<<<<FIXME>>>>\"\n",
      "  val_masks_path: \"/workspace/tao-experiments/data/<<<<FIXME>>>>\"\n",
      "  \n",
      "  test_images_path: \"/workspace/tao-experiments/data/images/val\"\n",
      "  \n",
      "  data_class_config {\n",
      "    target_classes {\n",
      "      name: \"notflood\"\n",
      "      mapping_class: \"notflood\"\n",
      "      label_id: 0\n",
      "    }\n",
      "    target_classes {\n",
      "      name: \"flood\"\n",
      "      mapping_class: \"flood\"\n",
      "      label_id: 255\n",
      "    }\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n",
      "model_config {\n",
      "  model_input_width: <<<<FIXME>>>>\n",
      "  model_input_height: <<<<FIXME>>>>\n",
      "  model_input_channels: <<<<FIXME>>>>\n",
      "  num_layers: 18\n",
      "  all_projections: true\n",
      "  arch: \"resnet\"\n",
      "  use_batch_norm: true\n",
      "  training_precision {\n",
      "    backend_floatx: FLOAT32\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n",
      "training_config {\n",
      "  batch_size: 1\n",
      "  epochs: <<<<FIXME>>>>\n",
      "  log_summary_steps: 10\n",
      "  checkpoint_interval: 10\n",
      "  loss: \"cross_dice_sum\"\n",
      "  learning_rate: 0.0001\n",
      "  regularizer {\n",
      "    type: L2\n",
      "    weight: 2e-5\n",
      "  }\n",
      "  optimizer {\n",
      "    adam {\n",
      "      epsilon: 9.99999993923e-09\n",
      "      beta1: 0.899999976158\n",
      "      beta2: 0.999000012875\n",
      "    }\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# combining configuration components in separate files and writing into one\n",
    "!cat $LOCAL_SPECS_DIR/resnet18/dataset_config.txt \\\n",
    "     $LOCAL_SPECS_DIR/resnet18/model_config.txt \\\n",
    "     $LOCAL_SPECS_DIR/resnet18/training_config.txt \\\n",
    "     > $LOCAL_SPECS_DIR/resnet18/combined_config.txt\n",
    "!cat $LOCAL_SPECS_DIR/resnet18/combined_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ded461-e7f3-4d20-b406-e1a0b309eb29",
   "metadata": {},
   "source": [
    "<p><img src='images/important.png' width=720></p>\n",
    "\n",
    "Note that we must leave an empty new line at the end of each text file to ensure the `combined_config.txt` is created properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b587b-d099-48ab-be87-3e3c8b3f41af",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s2-e2'></a>\n",
    "### Exercise #2 - Modify Dataset Config ###\n",
    "The dataloader defines the path of the data that the model will train on and the class mapping for the classes in the dataset. We have previously generated images and masks for the training datasets. To use the newly generated training data, update the `dataset_config` parameter in the spec file to reference the correct directory. \n",
    "* `dataset (str)`: The input type dataset used. The currently supported dataset is `custom` to the user. Open-source datasets will be added in the future. \n",
    "* `augment (bool)`: If the input should be augmented online while training. When using one’s own dataset to train and fine-tune a model, the dataset can be augmented while training to introduce variations in the dataset. This is known as **online augmentation**. This is very useful in training as data variation improves the overall quality of the model and prevents [overfitting](https://en.wikipedia.org/wiki/Overfitting). Training a deep neural network requires large amounts of annotated data, which can be a manual and expensive process. Furthermore, it can be difficult to estimate all the corner cases that the network may go through. The TAO Toolkit provides _spatial augmentation_ (resize and flip) and _color space augmentation_ (brightness) to create synthetic data variations. \n",
    "* `augmentation_config (dict)`: \n",
    "    * `spatial_augmentation (dict)`: Supports spatial augmentation such as flip, zoom, and translate. \n",
    "        * `hflip_probability (float)`: Probability to flip an input image horizontally. \n",
    "        * `vflip_probability (float)`: Probability to flip an input image vertically. \n",
    "        * `crop_and_resize_prob (float)`\n",
    "    * `brightness_augmentation (dict)`: Configures the color space transformation. \n",
    "        * `delta (float)`: Adjust brightness using delta value. \n",
    "* `input_image_type (str)`: The input image type to indicate if input image is `grayscale` or `color` (RGB). \n",
    "* `train_images_path (str)`, `train_masks_path (str)`, `val_images_path (str)`, `val_masks_path (str)`, `test_images_path (str)`: The path string for train images, train masks, validation images, validation masks, and test images (optional). \n",
    "* `data_class_config (dict)`: Proto dictionary that contains information of training classes as part of target_classes proto which is described below.\n",
    "    * `target_classes (dict)`: The repeated field for every training class. The following are required parameters for the `target_classes` config:\n",
    "        * `name (str)`: The name of the target class. \n",
    "        * `mapping_class (str)`: The name of the mapping class for the target class. If the class needs to be trained as is, then name and mapping_class should be the same.\n",
    "        * `label_id (int)`: The pixel that belongs to this target class is assigned this label_id value in the mask image.\n",
    "\n",
    "_Note the supported image extension formats for training images are “.png”, “.jpg”, “.jpeg”, “.PNG”, “.JPG”, and “.JPEG”._\n",
    "\n",
    "**Instructions**:<br>\n",
    "* Modify the `dataset_config`[(here)](tao_project/spec_files/resnet18/dataset_config.txt) section of the training configuration file by changing the `<FIXME>`s into acceptable values and **save changes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d107a8a2-ffd6-4bc3-9a89-1062afdd53f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_config {\n",
      "  dataset: \"custom\"\n",
      "  augment: true\n",
      "  augmentation_config {\n",
      "    spatial_augmentation {\n",
      "      hflip_probability : 0.5\n",
      "      vflip_probability : 0.5\n",
      "      crop_and_resize_prob : 0.5\n",
      "    }\n",
      "  }\n",
      "  input_image_type: \"color\"\n",
      "  train_images_path:\"/workspace/tao-experiments/data/images/train\"\n",
      "  train_masks_path:\"/workspace/tao-experiments/data/masks/train\"\n",
      "\n",
      "  val_images_path:\"/workspace/tao-experiments/data/images/val\"\n",
      "  val_masks_path:\"/workspace/tao-experiments/data/masks/val\"\n",
      "  \n",
      "  test_images_path:\"/workspace/tao-experiments/data/images/val\"\n",
      "  \n",
      "  data_class_config {\n",
      "    target_classes {\n",
      "      name: \"notflood\"\n",
      "      mapping_class: \"notflood\"\n",
      "      label_id: 0\n",
      "    }\n",
      "    target_classes {\n",
      "      name: \"flood\"\n",
      "      mapping_class: \"flood\"\n",
      "      label_id: 255\n",
      "    }\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# read the config file\n",
    "!cat $LOCAL_SPECS_DIR/resnet18/dataset_config.txt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19bc4ae2-6f1d-4204-aecb-7316a1b33ec7",
   "metadata": {
    "tags": []
   },
   "source": [
    "dataset_config {\n",
    "  dataset: \"custom\"\n",
    "  augment: true\n",
    "  augmentation_config {\n",
    "    spatial_augmentation {\n",
    "      hflip_probability : 0.5\n",
    "      vflip_probability : 0.5\n",
    "      crop_and_resize_prob : 0.5\n",
    "    }\n",
    "  }\n",
    "  input_image_type: \"color\"\n",
    "  train_images_path:\"/workspace/tao-experiments/data/images/train\"\n",
    "  train_masks_path:\"/workspace/tao-experiments/data/masks/train\"\n",
    "\n",
    "  val_images_path:\"/workspace/tao-experiments/data/images/val\"\n",
    "  val_masks_path:\"/workspace/tao-experiments/data/masks/val\"\n",
    "  \n",
    "  test_images_path:\"/workspace/tao-experiments/data/images/val\"\n",
    "  \n",
    "  data_class_config {\n",
    "    target_classes {\n",
    "      name: \"notflood\"\n",
    "      mapping_class: \"notflood\"\n",
    "      label_id: 0\n",
    "    }\n",
    "    target_classes {\n",
    "      name: \"flood\"\n",
    "      mapping_class: \"flood\"\n",
    "      label_id: 255\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f334dfe-04fc-455a-a94d-9624cfb85c1a",
   "metadata": {},
   "source": [
    "Click ... to show **solution**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9eb38b-7041-4078-b4ad-60ea7086e2fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s2-e3'></a>\n",
    "### Exercise #3 - Modify Model Config ###\n",
    "The segmentation model can be configured using the `model_config` option in the spec file. \n",
    "* `all_projections (bool)`: For templates with shortcut connections, this parameter defines whether all shortcuts should be instantiated with 1x1 projection layers, irrespective of a change in stride across the input and output. \n",
    "* `arch (str)`: The architecture of the backbone feature extractor to be used for training. \n",
    "* `num_layers (int)`: The depth of the feature extractor for scalable templates. \n",
    "* `use_batch_norm (bool)`: A Boolean value that determines whether to use batch normalization layers or not. \n",
    "* `training_precision (dict)`: Contains a nested parameter that sets the precision of the back-end training framework. \n",
    "    * `backend_floatx`: The back-end training framework should be set to `FLOAT322`. \n",
    "* `initializer (choice)`: Initialization of convolutional layers. Supported initializations are `HE_UNIFORM`, `HE_NORMAL`, and `GLOROT_UNIFORM`. \n",
    "* `model_input_height (int)`: The model input height dimension of the model, which should be a multiple of 16.\n",
    "* `model_input_width (int)`: The model input width dimension of the model, which should be a multiple of 16.\n",
    "* `model_input_channels (int)`: The model-input channels dimension of the model, which should be set to 3 for a ResNet/VGG backbone. \n",
    "\n",
    "**Instructions**:<br>\n",
    "* Modify the `model_config`[(here)](tao_project/spec_files/resnet18/model_config.txt) section of the configuration file by changing the `<FIXME>`s into acceptable values and **save changes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ac8ebc-0ede-4d6f-b982-47f6bf649b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config {\n",
      "  model_input_width: 512\n",
      "  model_input_height: 512\n",
      "  model_input_channels: 3\n",
      "  num_layers: 18\n",
      "  all_projections: true\n",
      "  arch: \"resnet\"\n",
      "  use_batch_norm: true\n",
      "  training_precision {\n",
      "    backend_floatx: FLOAT32\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# read the config file\n",
    "!cat $LOCAL_SPECS_DIR/resnet18/model_config.txt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3798c024-75c6-45cf-ab2f-39519e766747",
   "metadata": {
    "tags": []
   },
   "source": [
    "model_config {\n",
    "  model_input_width: 512\n",
    "  model_input_height: 512\n",
    "  model_input_channels: 3\n",
    "  num_layers: 18\n",
    "  all_projections: true\n",
    "  arch: \"resnet\"\n",
    "  use_batch_norm: true\n",
    "  training_precision {\n",
    "    backend_floatx: FLOAT32\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7fc6a-fb9b-4238-8b33-f5621a0b650c",
   "metadata": {},
   "source": [
    "Click ... to show **solution**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc06f5-3044-43b6-a35d-f7338e21ea3d",
   "metadata": {},
   "source": [
    "<a name='s2-e4'></a>\n",
    "#### Exercise #4 - Modify Training Config ####\n",
    "The `training_config` describes the training and learning process. \n",
    "* `batch_size (int)`: The number of images per batch per gpu. \n",
    "* `epochs (int)`: The number of epochs to train the model. One epoch represents one iteration of training through the entire dataset. \n",
    "* `log_summary_steps (int)`: The summary-steps interval at which train details are printed to stdout. \n",
    "* `checkpoint_interval (int)`: The number of epochs interval at which the checkpoint is saved. \n",
    "* `loss (str)`: The loss to be used for segmentation. \n",
    "* `learning_rate (float)`: The learning-rate initialization value. \n",
    "* `regularizer (dict)`: This parameter configures the type and weight of the regularizer to be used during training. The two parameters include:\n",
    "    * `type (Choice)`: The type of the regularizer being used should be `L2` or `L1`. \n",
    "    * `weight (Float)`: The floating-point weight of the regularizer. \n",
    "* `optimizer (dict)`: This parameter defines which optimizer to use for training, and the parameters to configure it, namely:\n",
    "    * `adam`: \n",
    "        * `epsilon (float)`: Is a very small number to prevent any division by zero in the implementation. \n",
    "        * `beta1 (float)`.  \n",
    "        * `beta2 (float)`. \n",
    "* `activation (str)`: The activation to be used on the last layer supported is `softmax`. \n",
    "\n",
    "**Instructions**:<br>\n",
    "* Modify the `training_config`[(here)](tao_project/spec_files/resnet18/training_config.txt) section of the training configuration file by changing the `<FIXME>` into acceptable values and **save changes**. Typically, using a higher epochs count will improve model performance but takes longer time to complete. For the purpose of this exercise, we recommend starting with a low `n_epochs`, such as `10`, to allow the model to converge without taking too much time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73fff69-46a3-46a3-ad07-cf7947238405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_config {\n",
      "  batch_size: 1\n",
      "  epochs: 10\n",
      "  log_summary_steps: 10\n",
      "  checkpoint_interval: 10\n",
      "  loss: \"cross_dice_sum\"\n",
      "  learning_rate: 0.0001\n",
      "  regularizer {\n",
      "    type: L2\n",
      "    weight: 2e-5\n",
      "  }\n",
      "  optimizer {\n",
      "    adam {\n",
      "      epsilon: 9.99999993923e-09\n",
      "      beta1: 0.899999976158\n",
      "      beta2: 0.999000012875\n",
      "    }\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# read the config file\n",
    "!cat $LOCAL_SPECS_DIR/resnet18/training_config.txt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcdeb7d9-6d03-4614-8fec-c7e3dbc15988",
   "metadata": {
    "tags": []
   },
   "source": [
    "training_config {\n",
    "  batch_size: 1\n",
    "  epochs: 10\n",
    "  log_summary_steps: 10\n",
    "  checkpoint_interval: 10\n",
    "  loss: \"cross_dice_sum\"\n",
    "  learning_rate: 0.0001\n",
    "  regularizer {\n",
    "    type: L2\n",
    "    weight: 2e-5\n",
    "  }\n",
    "  optimizer {\n",
    "    adam {\n",
    "      epsilon: 9.99999993923e-09\n",
    "      beta1: 0.899999976158\n",
    "      beta2: 0.999000012875\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35245c3-e8e1-4d16-a97b-c2cd97325f00",
   "metadata": {},
   "source": [
    "Click ... to show **solution**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac10ab-9555-42fa-bf53-8a4c81daaedc",
   "metadata": {},
   "source": [
    "<a name='s2-2.5'></a>\n",
    "### Combine Configuration Files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67af8d63-2748-47b9-9bc1-ac561a34d6af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_config {\n",
      "  dataset: \"custom\"\n",
      "  augment: true\n",
      "  augmentation_config {\n",
      "    spatial_augmentation {\n",
      "      hflip_probability : 0.5\n",
      "      vflip_probability : 0.5\n",
      "      crop_and_resize_prob : 0.5\n",
      "    }\n",
      "  }\n",
      "  input_image_type: \"color\"\n",
      "  train_images_path:\"/workspace/tao-experiments/data/images/train\"\n",
      "  train_masks_path:\"/workspace/tao-experiments/data/masks/train\"\n",
      "\n",
      "  val_images_path:\"/workspace/tao-experiments/data/images/val\"\n",
      "  val_masks_path:\"/workspace/tao-experiments/data/masks/val\"\n",
      "  \n",
      "  test_images_path:\"/workspace/tao-experiments/data/images/val\"\n",
      "  \n",
      "  data_class_config {\n",
      "    target_classes {\n",
      "      name: \"notflood\"\n",
      "      mapping_class: \"notflood\"\n",
      "      label_id: 0\n",
      "    }\n",
      "    target_classes {\n",
      "      name: \"flood\"\n",
      "      mapping_class: \"flood\"\n",
      "      label_id: 255\n",
      "    }\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n",
      "model_config {\n",
      "  model_input_width: 512\n",
      "  model_input_height: 512\n",
      "  model_input_channels: 3\n",
      "  num_layers: 18\n",
      "  all_projections: true\n",
      "  arch: \"resnet\"\n",
      "  use_batch_norm: true\n",
      "  training_precision {\n",
      "    backend_floatx: FLOAT32\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n",
      "training_config {\n",
      "  batch_size: 1\n",
      "  epochs: 10\n",
      "  log_summary_steps: 10\n",
      "  checkpoint_interval: 10\n",
      "  loss: \"cross_dice_sum\"\n",
      "  learning_rate: 0.0001\n",
      "  regularizer {\n",
      "    type: L2\n",
      "    weight: 2e-5\n",
      "  }\n",
      "  optimizer {\n",
      "    adam {\n",
      "      epsilon: 9.99999993923e-09\n",
      "      beta1: 0.899999976158\n",
      "      beta2: 0.999000012875\n",
      "    }\n",
      "  }\n",
      "}\n",
      "########## LEAVE NEW LINE BELOW\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# combining configuration components in separate files and writing into one\n",
    "!cat $LOCAL_SPECS_DIR/resnet18/dataset_config.txt \\\n",
    "     $LOCAL_SPECS_DIR/resnet18/model_config.txt \\\n",
    "     $LOCAL_SPECS_DIR/resnet18/training_config.txt \\\n",
    "     > $LOCAL_SPECS_DIR/resnet18/combined_config.txt\n",
    "!cat $LOCAL_SPECS_DIR/resnet18/combined_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fcd57b-41cf-432e-b2f3-033140bb8799",
   "metadata": {},
   "source": [
    "<a name='s2-2.6'></a>\n",
    "### Initiate Model Training ###\n",
    "After preparing input data and setting up a spec file, we can start training the semantic segmentation model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "71e40905-6482-48dc-b81b-a5a5a9657f99",
   "metadata": {},
   "source": [
    "tao unet train [-h] -e <EXPERIMENT_SPEC_FILE>\n",
    "                    -r <RESULTS_DIR>\n",
    "                    -n <MODEL_NAME>\n",
    "                    -m <PRETRAINED_MODEL_FILE>\n",
    "                    -k <key>\n",
    "                    [-v Set Verbosity of the logger]\n",
    "                    [--gpus GPUS]\n",
    "                    [--gpu_index GPU_INDEX]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe0274-1990-48cf-b3d1-191d9e191f67",
   "metadata": {},
   "source": [
    "When using the `train` subtask, the `-e` argument indicates the path to the spec file, the `-r` argument indicates the result directory, and the `-k` indicates the key to _load_ the pre-trained weights. There are some arguments that might be useful such as `-n` to indicates the name of the final step model saved and `-m` to indicate the path to a pre-trained model to initialize. Based on how NGC names the model downloaded, we should use `/workspace/tao-experiments/unt/pretrained_resnet18/pretrained_semantic_segmentation_vresnet18/resnet_18.hdf5` to reference the pre-trained model.\n",
    "\n",
    "_Multi-GPU support can be enabled for those with the hardware using the `--gpus` argument. When running the training with more than one GPU, we will need to modify the `batch_size` and `learning_rate`. In most cases, scaling down the batch-size by a factor of NUM_GPU's or scaling up the learning rate by a factor of NUM_GPUs would be a good place to start._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9bd470c-9b7e-4aa2-b800-4e0734431b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# remove any previous training if exists\n",
    "!rm -rf $LOCAL_EXPERIMENT_DIR/resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8ba85-1a06-424e-a4ec-6461de7df0d2",
   "metadata": {},
   "source": [
    "<p><img src='images/important.png' width=720></p>\n",
    "\n",
    "While the TAO Toolkit is running, there may be some _TensorFlow deprecation_ warning messages that can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1683c791-8dd8-461c-8615-7dd4ebdac421",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 10:14:58,634 [INFO] root: Registry: ['nvcr.io']\n",
      "2023-10-09 10:14:58,805 [INFO] tlt.components.instance_handler.local_instance: Running command in container: nvcr.io/nvidia/tao/tao-toolkit-tf:v3.21.11-tf1.15.5-py3\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/hooks/checkpoint_saver_hook.py:21: The name tf.train.CheckpointSaverHook is deprecated. Please use tf.estimator.CheckpointSaverHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/hooks/pretrained_restore_hook.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/hooks/pretrained_restore_hook.py:23: The name tf.logging.WARN is deprecated. Please use tf.compat.v1.logging.WARN instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/scripts/train.py:410: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "Loading experiment spec at /workspace/tao-experiments/spec_files/resnet18/combined_config.txt.\n",
      "2023-10-09 10:15:04,339 [INFO] __main__: Loading experiment spec at /workspace/tao-experiments/spec_files/resnet18/combined_config.txt.\n",
      "2023-10-09 10:15:04,340 [INFO] iva.unet.spec_handler.spec_loader: Merging specification from /workspace/tao-experiments/spec_files/resnet18/combined_config.txt\n",
      "2023-10-09 10:15:04,342 [INFO] root: Initializing the pre-trained weights from /workspace/tao-experiments/unet/pretrained_resnet18/pretrained_semantic_segmentation_vresnet18/resnet_18.hdf5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2023-10-09 10:15:04,344 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2023-10-09 10:15:04,352 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2023-10-09 10:15:04,360 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2023-10-09 10:15:04,367 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2023-10-09 10:15:04,371 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2023-10-09 10:15:04,943 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2023-10-09 10:15:05,099 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2023-10-09 10:15:05,100 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2023-10-09 10:15:05,100 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2023-10-09 10:15:05,300 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "2023-10-09 10:15:05,678 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "2023-10-09 10:15:05,690 [INFO] iva.unet.model.utilities: Label Id 0: Train Id 0\n",
      "2023-10-09 10:15:05,690 [INFO] iva.unet.model.utilities: Label Id 255: Train Id 1\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/workspace/tao-experiments/unet/resnet18', '_tf_random_seed': None, '_save_summary_steps': 5, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 1\n",
      "inter_op_parallelism_threads: 38\n",
      "gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"0\"\n",
      "  force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': None, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc04e1e89e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "2023-10-09 10:15:05,691 [INFO] tensorflow: Using config: {'_model_dir': '/workspace/tao-experiments/unet/resnet18', '_tf_random_seed': None, '_save_summary_steps': 5, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 1\n",
      "inter_op_parallelism_threads: 38\n",
      "gpu_options {\n",
      "  allow_growth: true\n",
      "  visible_device_list: \"0\"\n",
      "  force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': None, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc04e1e89e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "\n",
      "Phase train: Total 334 files.\n",
      "2023-10-09 10:15:05,709 [INFO] iva.unet.model.utilities: The total number of training samples 334 and the batch size per                 GPU 1\n",
      "2023-10-09 10:15:05,709 [INFO] iva.unet.model.utilities: Steps per epoch taken: 334\n",
      "Running for 10 Epochs\n",
      "2023-10-09 10:15:05,710 [INFO] __main__: Running for 10 Epochs\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2023-10-09 10:15:05,710 [INFO] tensorflow: Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2023-10-09 10:15:06,009 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,044 [WARNING] tensorflow: Entity <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fc03b38bc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fc03b38bc80>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,056 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fc03b38bc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fc03b38bc80>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "2023-10-09 10:15:06,058 [WARNING] tensorflow: \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "/opt/nvidia/third_party/keras/tensorflow_backend.py:356: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
      "  self, _map_func_set_random_wrapper, num_parallel_calls=num_parallel_calls\n",
      "WARNING:tensorflow:Entity <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,066 [WARNING] tensorflow: Entity <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,072 [WARNING] tensorflow: Entity <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,077 [WARNING] tensorflow: Entity <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/utils/data_loader.py:451: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "2023-10-09 10:15:06,078 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/utils/data_loader.py:451: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf67104c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf67104c80>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,086 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf67104c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf67104c80>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7f598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7f598>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,093 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7f598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7f598>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "2023-10-09 10:15:06,154 [WARNING] tensorflow: The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7f950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7f950>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,167 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7f950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7f950>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,174 [WARNING] tensorflow: Entity <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fc04e1e8c18>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7fae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7fae8>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:15:06,184 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7fae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fbf65d7fae8>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "2023-10-09 10:15:06,199 [INFO] tensorflow: Calling model_fn.\n",
      "2023-10-09 10:15:06,199 [INFO] iva.unet.utils.model_fn: {'exec_mode': 'train', 'model_dir': '/workspace/tao-experiments/unet/resnet18', 'resize_padding': False, 'resize_method': 'BILINEAR', 'log_dir': None, 'batch_size': 1, 'learning_rate': 9.999999747378752e-05, 'activation': 'softmax', 'crossvalidation_idx': None, 'max_steps': None, 'regularizer_type': 2, 'weight_decay': 1.9999999494757503e-05, 'log_summary_steps': 10, 'warmup_steps': 0, 'augment': True, 'use_amp': False, 'use_trt': False, 'use_xla': False, 'loss': 'cross_dice_sum', 'epochs': 10, 'pretrained_weights_file': None, 'lr_scheduler': None, 'unet_model': <iva.unet.model.resnet_unet.ResnetUnet object at 0x7fbf65d86a90>, 'key': 'my_model_key', 'experiment_spec': dataset_config {\n",
      "  augment: true\n",
      "  dataset: \"custom\"\n",
      "  input_image_type: \"color\"\n",
      "  train_images_path: \"/workspace/tao-experiments/data/images/train\"\n",
      "  train_masks_path: \"/workspace/tao-experiments/data/masks/train\"\n",
      "  val_images_path: \"/workspace/tao-experiments/data/images/val\"\n",
      "  val_masks_path: \"/workspace/tao-experiments/data/masks/val\"\n",
      "  test_images_path: \"/workspace/tao-experiments/data/images/val\"\n",
      "  data_class_config {\n",
      "    target_classes {\n",
      "      name: \"notflood\"\n",
      "      mapping_class: \"notflood\"\n",
      "    }\n",
      "    target_classes {\n",
      "      name: \"flood\"\n",
      "      label_id: 255\n",
      "      mapping_class: \"flood\"\n",
      "    }\n",
      "  }\n",
      "  augmentation_config {\n",
      "    spatial_augmentation {\n",
      "      hflip_probability: 0.5\n",
      "      vflip_probability: 0.5\n",
      "      crop_and_resize_prob: 0.5\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_config {\n",
      "  num_layers: 18\n",
      "  use_batch_norm: true\n",
      "  training_precision {\n",
      "    backend_floatx: FLOAT32\n",
      "  }\n",
      "  arch: \"resnet\"\n",
      "  all_projections: true\n",
      "  model_input_height: 512\n",
      "  model_input_width: 512\n",
      "  model_input_channels: 3\n",
      "}\n",
      "training_config {\n",
      "  batch_size: 1\n",
      "  regularizer {\n",
      "    type: L2\n",
      "    weight: 1.9999999494757503e-05\n",
      "  }\n",
      "  optimizer {\n",
      "    adam {\n",
      "      epsilon: 9.99999993922529e-09\n",
      "      beta1: 0.8999999761581421\n",
      "      beta2: 0.9990000128746033\n",
      "    }\n",
      "  }\n",
      "  checkpoint_interval: 10\n",
      "  log_summary_steps: 10\n",
      "  learning_rate: 9.999999747378752e-05\n",
      "  loss: \"cross_dice_sum\"\n",
      "  epochs: 10\n",
      "}\n",
      ", 'seed': 0, 'benchmark': False, 'temp_dir': '/tmp/tmp_yu247yh', 'num_classes': 2, 'num_conf_mat_classes': 2, 'start_step': 0, 'checkpoint_interval': 10, 'model_json': None, 'load_graph': False, 'weights_monitor': False, 'phase': None}\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 512, 512)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 256, 256) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 256, 256) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 256, 256) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 128, 128) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 128, 128) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 128, 128) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 128, 128) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 128, 128) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 128, 128) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 128, 128) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 128, 128) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 128, 128) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 128, 128) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 128, 128) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 128, 128) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 128, 128) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 128, 128) 4160        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 128, 128) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 128, 128) 256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 128, 128) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 128, 128) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 64, 64)  73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 64, 64)  512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 64, 64)  0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 64, 64)  147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 64, 64)  8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 64, 64)  512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 64, 64)  512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 64, 64)  0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 64, 64)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 64, 64)  147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 64, 64)  512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 64, 64)  0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 64, 64)  147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 64, 64)  16512       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 64, 64)  512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 64, 64)  512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 64, 64)  0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 64, 64)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 32, 32)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 32, 32)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 32, 32)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 32, 32)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 32, 32)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 32, 32)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 32, 32)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 32, 32)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 32, 32)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 32, 32)  590080      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 32, 32)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 32, 32)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 32, 32)  590080      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 32, 32)  65792       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 32, 32)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 32, 32)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 32, 32)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 32, 32)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 32, 32)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 32, 32)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 32, 32)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 32, 32)  2359808     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 32, 32)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 32, 32)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 32, 32)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 32, 32)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 32, 32)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 32, 32)  2359808     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 32, 32)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 32, 32)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 32, 32)  2359808     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_shortcut (Conv2D) (None, 512, 32, 32)  262656      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 32, 32)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_shortcut (BatchNorm (None, 512, 32, 32)  2048        block_4b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 32, 32)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 32, 32)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 64, 64)  2097408     block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384, 64, 64)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 384, 64, 64)  1536        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 384, 64, 64)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 64, 64)  884992      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 64, 64)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 64, 64)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 524416      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192, 128, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 192, 128, 128 768         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 192, 128, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 221312      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 256, 256) 131136      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 256, 256 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 256, 256 512         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 256, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 256, 256) 73792       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 256, 256) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 256, 256) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 512, 512) 65600       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 512, 512) 256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 512, 512) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 512, 512) 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 512, 512) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 512, 512) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 2, 512, 512)  1154        activation_9[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 15,590,146\n",
      "Trainable params: 15,575,938\n",
      "Non-trainable params: 14,208\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/utils/model_fn.py:217: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "2023-10-09 10:15:07,668 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/utils/model_fn.py:217: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "2023-10-09 10:15:11,163 [INFO] tensorflow: Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2023-10-09 10:15:13,706 [INFO] tensorflow: Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "2023-10-09 10:15:15,178 [INFO] tensorflow: Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "2023-10-09 10:15:15,382 [INFO] tensorflow: Done running local_init_op.\n",
      "[GPU] Restoring pretrained weights from: /tmp/tmponimjwxf/model.ckpt-1\n",
      "2023-10-09 10:15:16,349 [INFO] iva.unet.hooks.pretrained_restore_hook: Pretrained weights loaded with success...\n",
      "\n",
      "INFO:tensorflow:Saving checkpoints for step-0.\n",
      "2023-10-09 10:15:21,813 [INFO] tensorflow: Saving checkpoints for step-0.\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/hooks/training_hook.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "2023-10-09 10:15:28,595 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/hooks/training_hook.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "Epoch: 0/10:, Cur-Step: 0, loss(cross_dice_sum): 1.20258, Running average loss:1.20258, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:40,114 [INFO] __main__: Epoch: 0/10:, Cur-Step: 0, loss(cross_dice_sum): 1.20258, Running average loss:1.20258, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 10, loss(cross_dice_sum): 1.19322, Running average loss:1.15062, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:49,247 [INFO] __main__: Epoch: 0/10:, Cur-Step: 10, loss(cross_dice_sum): 1.19322, Running average loss:1.15062, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 20, loss(cross_dice_sum): 0.47582, Running average loss:1.08606, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:50,561 [INFO] __main__: Epoch: 0/10:, Cur-Step: 20, loss(cross_dice_sum): 0.47582, Running average loss:1.08606, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 30, loss(cross_dice_sum): 1.01594, Running average loss:1.11012, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:51,883 [INFO] __main__: Epoch: 0/10:, Cur-Step: 30, loss(cross_dice_sum): 1.01594, Running average loss:1.11012, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 40, loss(cross_dice_sum): 0.90159, Running average loss:1.07811, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:53,198 [INFO] __main__: Epoch: 0/10:, Cur-Step: 40, loss(cross_dice_sum): 0.90159, Running average loss:1.07811, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 50, loss(cross_dice_sum): 0.76839, Running average loss:1.04772, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:54,526 [INFO] __main__: Epoch: 0/10:, Cur-Step: 50, loss(cross_dice_sum): 0.76839, Running average loss:1.04772, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 60, loss(cross_dice_sum): 0.49272, Running average loss:0.97656, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:55,853 [INFO] __main__: Epoch: 0/10:, Cur-Step: 60, loss(cross_dice_sum): 0.49272, Running average loss:0.97656, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 70, loss(cross_dice_sum): 0.64419, Running average loss:0.96018, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:57,178 [INFO] __main__: Epoch: 0/10:, Cur-Step: 70, loss(cross_dice_sum): 0.64419, Running average loss:0.96018, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 80, loss(cross_dice_sum): 2.18411, Running average loss:0.94007, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:58,496 [INFO] __main__: Epoch: 0/10:, Cur-Step: 80, loss(cross_dice_sum): 2.18411, Running average loss:0.94007, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 90, loss(cross_dice_sum): 0.26661, Running average loss:0.88055, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:15:59,815 [INFO] __main__: Epoch: 0/10:, Cur-Step: 90, loss(cross_dice_sum): 0.26661, Running average loss:0.88055, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 100, loss(cross_dice_sum): 0.17980, Running average loss:0.82498, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:01,230 [INFO] __main__: Epoch: 0/10:, Cur-Step: 100, loss(cross_dice_sum): 0.17980, Running average loss:0.82498, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 110, loss(cross_dice_sum): 1.30370, Running average loss:0.79162, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:02,553 [INFO] __main__: Epoch: 0/10:, Cur-Step: 110, loss(cross_dice_sum): 1.30370, Running average loss:0.79162, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 120, loss(cross_dice_sum): 0.28082, Running average loss:0.77429, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:03,886 [INFO] __main__: Epoch: 0/10:, Cur-Step: 120, loss(cross_dice_sum): 0.28082, Running average loss:0.77429, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 130, loss(cross_dice_sum): 1.27110, Running average loss:0.76117, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:05,214 [INFO] __main__: Epoch: 0/10:, Cur-Step: 130, loss(cross_dice_sum): 1.27110, Running average loss:0.76117, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 140, loss(cross_dice_sum): 0.33189, Running average loss:0.74636, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:06,540 [INFO] __main__: Epoch: 0/10:, Cur-Step: 140, loss(cross_dice_sum): 0.33189, Running average loss:0.74636, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 150, loss(cross_dice_sum): 0.61885, Running average loss:0.73886, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:07,868 [INFO] __main__: Epoch: 0/10:, Cur-Step: 150, loss(cross_dice_sum): 0.61885, Running average loss:0.73886, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 160, loss(cross_dice_sum): 0.34296, Running average loss:0.72350, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:09,202 [INFO] __main__: Epoch: 0/10:, Cur-Step: 160, loss(cross_dice_sum): 0.34296, Running average loss:0.72350, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 170, loss(cross_dice_sum): 0.16432, Running average loss:0.70366, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:10,545 [INFO] __main__: Epoch: 0/10:, Cur-Step: 170, loss(cross_dice_sum): 0.16432, Running average loss:0.70366, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 180, loss(cross_dice_sum): 0.22096, Running average loss:0.68426, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:11,882 [INFO] __main__: Epoch: 0/10:, Cur-Step: 180, loss(cross_dice_sum): 0.22096, Running average loss:0.68426, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 190, loss(cross_dice_sum): 0.37377, Running average loss:0.67374, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:13,214 [INFO] __main__: Epoch: 0/10:, Cur-Step: 190, loss(cross_dice_sum): 0.37377, Running average loss:0.67374, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 200, loss(cross_dice_sum): 1.63446, Running average loss:0.66296, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:14,548 [INFO] __main__: Epoch: 0/10:, Cur-Step: 200, loss(cross_dice_sum): 1.63446, Running average loss:0.66296, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 210, loss(cross_dice_sum): 0.19424, Running average loss:0.65442, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:15,886 [INFO] __main__: Epoch: 0/10:, Cur-Step: 210, loss(cross_dice_sum): 0.19424, Running average loss:0.65442, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 220, loss(cross_dice_sum): 0.58888, Running average loss:0.63972, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:17,226 [INFO] __main__: Epoch: 0/10:, Cur-Step: 220, loss(cross_dice_sum): 0.58888, Running average loss:0.63972, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 230, loss(cross_dice_sum): 0.44621, Running average loss:0.62455, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:18,572 [INFO] __main__: Epoch: 0/10:, Cur-Step: 230, loss(cross_dice_sum): 0.44621, Running average loss:0.62455, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 240, loss(cross_dice_sum): 0.24290, Running average loss:0.61618, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:19,907 [INFO] __main__: Epoch: 0/10:, Cur-Step: 240, loss(cross_dice_sum): 0.24290, Running average loss:0.61618, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 250, loss(cross_dice_sum): 0.99286, Running average loss:0.60880, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:21,247 [INFO] __main__: Epoch: 0/10:, Cur-Step: 250, loss(cross_dice_sum): 0.99286, Running average loss:0.60880, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 260, loss(cross_dice_sum): 0.30686, Running average loss:0.60093, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:22,582 [INFO] __main__: Epoch: 0/10:, Cur-Step: 260, loss(cross_dice_sum): 0.30686, Running average loss:0.60093, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 270, loss(cross_dice_sum): 0.18076, Running average loss:0.60214, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:23,921 [INFO] __main__: Epoch: 0/10:, Cur-Step: 270, loss(cross_dice_sum): 0.18076, Running average loss:0.60214, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 280, loss(cross_dice_sum): 0.56793, Running average loss:0.59593, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:25,258 [INFO] __main__: Epoch: 0/10:, Cur-Step: 280, loss(cross_dice_sum): 0.56793, Running average loss:0.59593, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 290, loss(cross_dice_sum): 0.58991, Running average loss:0.60310, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:26,597 [INFO] __main__: Epoch: 0/10:, Cur-Step: 290, loss(cross_dice_sum): 0.58991, Running average loss:0.60310, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 300, loss(cross_dice_sum): 0.47139, Running average loss:0.59926, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:27,941 [INFO] __main__: Epoch: 0/10:, Cur-Step: 300, loss(cross_dice_sum): 0.47139, Running average loss:0.59926, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 310, loss(cross_dice_sum): 0.27113, Running average loss:0.59973, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:29,281 [INFO] __main__: Epoch: 0/10:, Cur-Step: 310, loss(cross_dice_sum): 0.27113, Running average loss:0.59973, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 320, loss(cross_dice_sum): 0.37271, Running average loss:0.59314, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:30,625 [INFO] __main__: Epoch: 0/10:, Cur-Step: 320, loss(cross_dice_sum): 0.37271, Running average loss:0.59314, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 0/10:, Cur-Step: 330, loss(cross_dice_sum): 0.17547, Running average loss:0.58494, Time taken: 0:00:00 ETA: 0:00:00\n",
      "2023-10-09 10:16:31,960 [INFO] __main__: Epoch: 0/10:, Cur-Step: 330, loss(cross_dice_sum): 0.17547, Running average loss:0.58494, Time taken: 0:00:00 ETA: 0:00:00\n",
      "Epoch: 1/10:, Cur-Step: 340, loss(cross_dice_sum): 1.64777, Running average loss:0.47733, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:33,306 [INFO] __main__: Epoch: 1/10:, Cur-Step: 340, loss(cross_dice_sum): 1.64777, Running average loss:0.47733, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 350, loss(cross_dice_sum): 1.22924, Running average loss:0.46169, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:34,657 [INFO] __main__: Epoch: 1/10:, Cur-Step: 350, loss(cross_dice_sum): 1.22924, Running average loss:0.46169, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 360, loss(cross_dice_sum): 0.41037, Running average loss:0.41793, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:36,003 [INFO] __main__: Epoch: 1/10:, Cur-Step: 360, loss(cross_dice_sum): 0.41037, Running average loss:0.41793, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 370, loss(cross_dice_sum): 0.84205, Running average loss:0.44324, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:37,350 [INFO] __main__: Epoch: 1/10:, Cur-Step: 370, loss(cross_dice_sum): 0.84205, Running average loss:0.44324, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 380, loss(cross_dice_sum): 0.18382, Running average loss:0.46983, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:38,692 [INFO] __main__: Epoch: 1/10:, Cur-Step: 380, loss(cross_dice_sum): 0.18382, Running average loss:0.46983, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 390, loss(cross_dice_sum): 0.21407, Running average loss:0.50273, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:40,041 [INFO] __main__: Epoch: 1/10:, Cur-Step: 390, loss(cross_dice_sum): 0.21407, Running average loss:0.50273, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 400, loss(cross_dice_sum): 0.59917, Running average loss:0.48733, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:41,406 [INFO] __main__: Epoch: 1/10:, Cur-Step: 400, loss(cross_dice_sum): 0.59917, Running average loss:0.48733, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 410, loss(cross_dice_sum): 0.21481, Running average loss:0.45831, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:42,752 [INFO] __main__: Epoch: 1/10:, Cur-Step: 410, loss(cross_dice_sum): 0.21481, Running average loss:0.45831, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 420, loss(cross_dice_sum): 0.33199, Running average loss:0.44441, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:44,100 [INFO] __main__: Epoch: 1/10:, Cur-Step: 420, loss(cross_dice_sum): 0.33199, Running average loss:0.44441, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 430, loss(cross_dice_sum): 0.16092, Running average loss:0.44590, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:45,451 [INFO] __main__: Epoch: 1/10:, Cur-Step: 430, loss(cross_dice_sum): 0.16092, Running average loss:0.44590, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 440, loss(cross_dice_sum): 0.68592, Running average loss:0.44580, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:46,798 [INFO] __main__: Epoch: 1/10:, Cur-Step: 440, loss(cross_dice_sum): 0.68592, Running average loss:0.44580, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 450, loss(cross_dice_sum): 0.21714, Running average loss:0.44505, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:48,151 [INFO] __main__: Epoch: 1/10:, Cur-Step: 450, loss(cross_dice_sum): 0.21714, Running average loss:0.44505, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 460, loss(cross_dice_sum): 0.20253, Running average loss:0.43442, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:49,490 [INFO] __main__: Epoch: 1/10:, Cur-Step: 460, loss(cross_dice_sum): 0.20253, Running average loss:0.43442, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 470, loss(cross_dice_sum): 0.26606, Running average loss:0.42815, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:50,840 [INFO] __main__: Epoch: 1/10:, Cur-Step: 470, loss(cross_dice_sum): 0.26606, Running average loss:0.42815, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 480, loss(cross_dice_sum): 0.16066, Running average loss:0.42545, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:52,191 [INFO] __main__: Epoch: 1/10:, Cur-Step: 480, loss(cross_dice_sum): 0.16066, Running average loss:0.42545, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 490, loss(cross_dice_sum): 0.17515, Running average loss:0.43895, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:53,540 [INFO] __main__: Epoch: 1/10:, Cur-Step: 490, loss(cross_dice_sum): 0.17515, Running average loss:0.43895, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 500, loss(cross_dice_sum): 1.29304, Running average loss:0.44571, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:54,877 [INFO] __main__: Epoch: 1/10:, Cur-Step: 500, loss(cross_dice_sum): 1.29304, Running average loss:0.44571, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 510, loss(cross_dice_sum): 0.48185, Running average loss:0.43742, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:56,220 [INFO] __main__: Epoch: 1/10:, Cur-Step: 510, loss(cross_dice_sum): 0.48185, Running average loss:0.43742, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 520, loss(cross_dice_sum): 0.44096, Running average loss:0.43659, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:57,573 [INFO] __main__: Epoch: 1/10:, Cur-Step: 520, loss(cross_dice_sum): 0.44096, Running average loss:0.43659, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 530, loss(cross_dice_sum): 0.18966, Running average loss:0.44051, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:16:58,913 [INFO] __main__: Epoch: 1/10:, Cur-Step: 530, loss(cross_dice_sum): 0.18966, Running average loss:0.44051, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 540, loss(cross_dice_sum): 0.33232, Running average loss:0.43765, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:00,264 [INFO] __main__: Epoch: 1/10:, Cur-Step: 540, loss(cross_dice_sum): 0.33232, Running average loss:0.43765, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 550, loss(cross_dice_sum): 0.53094, Running average loss:0.43743, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:01,639 [INFO] __main__: Epoch: 1/10:, Cur-Step: 550, loss(cross_dice_sum): 0.53094, Running average loss:0.43743, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 560, loss(cross_dice_sum): 0.21864, Running average loss:0.43618, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:02,998 [INFO] __main__: Epoch: 1/10:, Cur-Step: 560, loss(cross_dice_sum): 0.21864, Running average loss:0.43618, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 570, loss(cross_dice_sum): 0.64493, Running average loss:0.43559, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:04,355 [INFO] __main__: Epoch: 1/10:, Cur-Step: 570, loss(cross_dice_sum): 0.64493, Running average loss:0.43559, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 580, loss(cross_dice_sum): 0.30938, Running average loss:0.43357, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:05,715 [INFO] __main__: Epoch: 1/10:, Cur-Step: 580, loss(cross_dice_sum): 0.30938, Running average loss:0.43357, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 590, loss(cross_dice_sum): 0.24564, Running average loss:0.43125, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:07,077 [INFO] __main__: Epoch: 1/10:, Cur-Step: 590, loss(cross_dice_sum): 0.24564, Running average loss:0.43125, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 600, loss(cross_dice_sum): 0.19031, Running average loss:0.42402, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:08,447 [INFO] __main__: Epoch: 1/10:, Cur-Step: 600, loss(cross_dice_sum): 0.19031, Running average loss:0.42402, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 610, loss(cross_dice_sum): 0.72622, Running average loss:0.42947, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:09,815 [INFO] __main__: Epoch: 1/10:, Cur-Step: 610, loss(cross_dice_sum): 0.72622, Running average loss:0.42947, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 620, loss(cross_dice_sum): 0.18100, Running average loss:0.42624, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:11,171 [INFO] __main__: Epoch: 1/10:, Cur-Step: 620, loss(cross_dice_sum): 0.18100, Running average loss:0.42624, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 630, loss(cross_dice_sum): 0.27256, Running average loss:0.42868, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:12,537 [INFO] __main__: Epoch: 1/10:, Cur-Step: 630, loss(cross_dice_sum): 0.27256, Running average loss:0.42868, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 640, loss(cross_dice_sum): 0.45922, Running average loss:0.42542, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:13,889 [INFO] __main__: Epoch: 1/10:, Cur-Step: 640, loss(cross_dice_sum): 0.45922, Running average loss:0.42542, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 650, loss(cross_dice_sum): 0.79381, Running average loss:0.42451, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:15,248 [INFO] __main__: Epoch: 1/10:, Cur-Step: 650, loss(cross_dice_sum): 0.79381, Running average loss:0.42451, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 1/10:, Cur-Step: 660, loss(cross_dice_sum): 0.20747, Running average loss:0.42972, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "2023-10-09 10:17:16,615 [INFO] __main__: Epoch: 1/10:, Cur-Step: 660, loss(cross_dice_sum): 0.20747, Running average loss:0.42972, Time taken: 0:01:26.657077 ETA: 0:12:59.913692\n",
      "Epoch: 2/10:, Cur-Step: 670, loss(cross_dice_sum): 0.31497, Running average loss:0.32162, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:17,977 [INFO] __main__: Epoch: 2/10:, Cur-Step: 670, loss(cross_dice_sum): 0.31497, Running average loss:0.32162, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 680, loss(cross_dice_sum): 0.45158, Running average loss:0.48424, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:19,343 [INFO] __main__: Epoch: 2/10:, Cur-Step: 680, loss(cross_dice_sum): 0.45158, Running average loss:0.48424, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 690, loss(cross_dice_sum): 0.42342, Running average loss:0.47551, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:20,709 [INFO] __main__: Epoch: 2/10:, Cur-Step: 690, loss(cross_dice_sum): 0.42342, Running average loss:0.47551, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 700, loss(cross_dice_sum): 0.73824, Running average loss:0.44999, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:22,082 [INFO] __main__: Epoch: 2/10:, Cur-Step: 700, loss(cross_dice_sum): 0.73824, Running average loss:0.44999, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 710, loss(cross_dice_sum): 0.17871, Running average loss:0.46778, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:23,456 [INFO] __main__: Epoch: 2/10:, Cur-Step: 710, loss(cross_dice_sum): 0.17871, Running average loss:0.46778, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 720, loss(cross_dice_sum): 0.55088, Running average loss:0.47083, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:24,828 [INFO] __main__: Epoch: 2/10:, Cur-Step: 720, loss(cross_dice_sum): 0.55088, Running average loss:0.47083, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 730, loss(cross_dice_sum): 0.60090, Running average loss:0.45976, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:26,202 [INFO] __main__: Epoch: 2/10:, Cur-Step: 730, loss(cross_dice_sum): 0.60090, Running average loss:0.45976, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 740, loss(cross_dice_sum): 0.21855, Running average loss:0.44020, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:27,565 [INFO] __main__: Epoch: 2/10:, Cur-Step: 740, loss(cross_dice_sum): 0.21855, Running average loss:0.44020, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 750, loss(cross_dice_sum): 0.15482, Running average loss:0.43034, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:28,928 [INFO] __main__: Epoch: 2/10:, Cur-Step: 750, loss(cross_dice_sum): 0.15482, Running average loss:0.43034, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 760, loss(cross_dice_sum): 0.44324, Running average loss:0.44296, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:30,292 [INFO] __main__: Epoch: 2/10:, Cur-Step: 760, loss(cross_dice_sum): 0.44324, Running average loss:0.44296, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 770, loss(cross_dice_sum): 0.44853, Running average loss:0.43683, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:31,663 [INFO] __main__: Epoch: 2/10:, Cur-Step: 770, loss(cross_dice_sum): 0.44853, Running average loss:0.43683, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 780, loss(cross_dice_sum): 0.48881, Running average loss:0.43545, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:33,031 [INFO] __main__: Epoch: 2/10:, Cur-Step: 780, loss(cross_dice_sum): 0.48881, Running average loss:0.43545, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 790, loss(cross_dice_sum): 0.32478, Running average loss:0.42901, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:34,406 [INFO] __main__: Epoch: 2/10:, Cur-Step: 790, loss(cross_dice_sum): 0.32478, Running average loss:0.42901, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 800, loss(cross_dice_sum): 0.21536, Running average loss:0.42335, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:35,774 [INFO] __main__: Epoch: 2/10:, Cur-Step: 800, loss(cross_dice_sum): 0.21536, Running average loss:0.42335, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 810, loss(cross_dice_sum): 0.77728, Running average loss:0.42606, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:37,147 [INFO] __main__: Epoch: 2/10:, Cur-Step: 810, loss(cross_dice_sum): 0.77728, Running average loss:0.42606, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 820, loss(cross_dice_sum): 0.22568, Running average loss:0.42176, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:38,522 [INFO] __main__: Epoch: 2/10:, Cur-Step: 820, loss(cross_dice_sum): 0.22568, Running average loss:0.42176, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 830, loss(cross_dice_sum): 0.15772, Running average loss:0.41548, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:39,885 [INFO] __main__: Epoch: 2/10:, Cur-Step: 830, loss(cross_dice_sum): 0.15772, Running average loss:0.41548, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 840, loss(cross_dice_sum): 0.16853, Running average loss:0.41388, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:41,260 [INFO] __main__: Epoch: 2/10:, Cur-Step: 840, loss(cross_dice_sum): 0.16853, Running average loss:0.41388, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 850, loss(cross_dice_sum): 0.46676, Running average loss:0.40680, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:42,630 [INFO] __main__: Epoch: 2/10:, Cur-Step: 850, loss(cross_dice_sum): 0.46676, Running average loss:0.40680, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 860, loss(cross_dice_sum): 0.59867, Running average loss:0.41893, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:44,002 [INFO] __main__: Epoch: 2/10:, Cur-Step: 860, loss(cross_dice_sum): 0.59867, Running average loss:0.41893, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 870, loss(cross_dice_sum): 0.20786, Running average loss:0.42514, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:45,373 [INFO] __main__: Epoch: 2/10:, Cur-Step: 870, loss(cross_dice_sum): 0.20786, Running average loss:0.42514, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 880, loss(cross_dice_sum): 0.21065, Running average loss:0.41873, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:46,742 [INFO] __main__: Epoch: 2/10:, Cur-Step: 880, loss(cross_dice_sum): 0.21065, Running average loss:0.41873, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 890, loss(cross_dice_sum): 0.18025, Running average loss:0.40997, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:48,110 [INFO] __main__: Epoch: 2/10:, Cur-Step: 890, loss(cross_dice_sum): 0.18025, Running average loss:0.40997, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 900, loss(cross_dice_sum): 0.43871, Running average loss:0.40701, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:49,478 [INFO] __main__: Epoch: 2/10:, Cur-Step: 900, loss(cross_dice_sum): 0.43871, Running average loss:0.40701, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 910, loss(cross_dice_sum): 0.17886, Running average loss:0.41176, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:50,854 [INFO] __main__: Epoch: 2/10:, Cur-Step: 910, loss(cross_dice_sum): 0.17886, Running average loss:0.41176, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 920, loss(cross_dice_sum): 0.26805, Running average loss:0.40563, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:52,215 [INFO] __main__: Epoch: 2/10:, Cur-Step: 920, loss(cross_dice_sum): 0.26805, Running average loss:0.40563, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 930, loss(cross_dice_sum): 0.24528, Running average loss:0.40442, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:53,585 [INFO] __main__: Epoch: 2/10:, Cur-Step: 930, loss(cross_dice_sum): 0.24528, Running average loss:0.40442, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 940, loss(cross_dice_sum): 0.33911, Running average loss:0.40677, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:54,937 [INFO] __main__: Epoch: 2/10:, Cur-Step: 940, loss(cross_dice_sum): 0.33911, Running average loss:0.40677, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 950, loss(cross_dice_sum): 0.63601, Running average loss:0.40533, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:56,295 [INFO] __main__: Epoch: 2/10:, Cur-Step: 950, loss(cross_dice_sum): 0.63601, Running average loss:0.40533, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 960, loss(cross_dice_sum): 0.77231, Running average loss:0.40122, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:57,663 [INFO] __main__: Epoch: 2/10:, Cur-Step: 960, loss(cross_dice_sum): 0.77231, Running average loss:0.40122, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 970, loss(cross_dice_sum): 0.27679, Running average loss:0.40297, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:17:59,035 [INFO] __main__: Epoch: 2/10:, Cur-Step: 970, loss(cross_dice_sum): 0.27679, Running average loss:0.40297, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 980, loss(cross_dice_sum): 0.32181, Running average loss:0.39990, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:18:00,410 [INFO] __main__: Epoch: 2/10:, Cur-Step: 980, loss(cross_dice_sum): 0.32181, Running average loss:0.39990, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 990, loss(cross_dice_sum): 0.17678, Running average loss:0.39878, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:18:01,786 [INFO] __main__: Epoch: 2/10:, Cur-Step: 990, loss(cross_dice_sum): 0.17678, Running average loss:0.39878, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 2/10:, Cur-Step: 1000, loss(cross_dice_sum): 0.15396, Running average loss:0.39673, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "2023-10-09 10:18:03,143 [INFO] __main__: Epoch: 2/10:, Cur-Step: 1000, loss(cross_dice_sum): 0.15396, Running average loss:0.39673, Time taken: 0:00:45.333766 ETA: 0:06:02.670124\n",
      "Epoch: 3/10:, Cur-Step: 1010, loss(cross_dice_sum): 0.38235, Running average loss:0.42069, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:04,517 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1010, loss(cross_dice_sum): 0.38235, Running average loss:0.42069, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1020, loss(cross_dice_sum): 0.15313, Running average loss:0.44296, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:05,894 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1020, loss(cross_dice_sum): 0.15313, Running average loss:0.44296, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1030, loss(cross_dice_sum): 0.72490, Running average loss:0.41189, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:07,270 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1030, loss(cross_dice_sum): 0.72490, Running average loss:0.41189, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1040, loss(cross_dice_sum): 0.33404, Running average loss:0.42840, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:08,643 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1040, loss(cross_dice_sum): 0.33404, Running average loss:0.42840, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1050, loss(cross_dice_sum): 0.23299, Running average loss:0.40830, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:10,026 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1050, loss(cross_dice_sum): 0.23299, Running average loss:0.40830, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1060, loss(cross_dice_sum): 0.27176, Running average loss:0.39572, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:11,399 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1060, loss(cross_dice_sum): 0.27176, Running average loss:0.39572, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1070, loss(cross_dice_sum): 0.22409, Running average loss:0.38941, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:12,768 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1070, loss(cross_dice_sum): 0.22409, Running average loss:0.38941, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1080, loss(cross_dice_sum): 0.28050, Running average loss:0.38305, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:14,147 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1080, loss(cross_dice_sum): 0.28050, Running average loss:0.38305, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1090, loss(cross_dice_sum): 0.15331, Running average loss:0.38404, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:15,515 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1090, loss(cross_dice_sum): 0.15331, Running average loss:0.38404, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1100, loss(cross_dice_sum): 0.18822, Running average loss:0.38404, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:16,883 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1100, loss(cross_dice_sum): 0.18822, Running average loss:0.38404, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1110, loss(cross_dice_sum): 0.16085, Running average loss:0.36792, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:18,257 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1110, loss(cross_dice_sum): 0.16085, Running average loss:0.36792, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1120, loss(cross_dice_sum): 0.25306, Running average loss:0.37983, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:19,641 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1120, loss(cross_dice_sum): 0.25306, Running average loss:0.37983, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1130, loss(cross_dice_sum): 0.64666, Running average loss:0.38196, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:21,020 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1130, loss(cross_dice_sum): 0.64666, Running average loss:0.38196, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1140, loss(cross_dice_sum): 0.16981, Running average loss:0.37801, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:22,403 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1140, loss(cross_dice_sum): 0.16981, Running average loss:0.37801, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1150, loss(cross_dice_sum): 0.85765, Running average loss:0.37698, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:23,778 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1150, loss(cross_dice_sum): 0.85765, Running average loss:0.37698, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1160, loss(cross_dice_sum): 0.26749, Running average loss:0.36756, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:25,149 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1160, loss(cross_dice_sum): 0.26749, Running average loss:0.36756, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1170, loss(cross_dice_sum): 0.44215, Running average loss:0.36446, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:26,521 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1170, loss(cross_dice_sum): 0.44215, Running average loss:0.36446, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1180, loss(cross_dice_sum): 0.21502, Running average loss:0.36241, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:27,897 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1180, loss(cross_dice_sum): 0.21502, Running average loss:0.36241, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1190, loss(cross_dice_sum): 0.52750, Running average loss:0.36026, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:29,263 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1190, loss(cross_dice_sum): 0.52750, Running average loss:0.36026, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1200, loss(cross_dice_sum): 0.25524, Running average loss:0.35814, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:30,644 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1200, loss(cross_dice_sum): 0.25524, Running average loss:0.35814, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1210, loss(cross_dice_sum): 0.22841, Running average loss:0.35897, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:32,026 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1210, loss(cross_dice_sum): 0.22841, Running average loss:0.35897, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1220, loss(cross_dice_sum): 0.19957, Running average loss:0.37003, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:33,408 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1220, loss(cross_dice_sum): 0.19957, Running average loss:0.37003, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1230, loss(cross_dice_sum): 0.27783, Running average loss:0.37062, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:34,793 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1230, loss(cross_dice_sum): 0.27783, Running average loss:0.37062, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1240, loss(cross_dice_sum): 0.17838, Running average loss:0.37498, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:36,162 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1240, loss(cross_dice_sum): 0.17838, Running average loss:0.37498, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1250, loss(cross_dice_sum): 0.19944, Running average loss:0.37030, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:37,536 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1250, loss(cross_dice_sum): 0.19944, Running average loss:0.37030, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1260, loss(cross_dice_sum): 0.14562, Running average loss:0.36659, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:38,913 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1260, loss(cross_dice_sum): 0.14562, Running average loss:0.36659, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1270, loss(cross_dice_sum): 0.52895, Running average loss:0.36406, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:40,290 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1270, loss(cross_dice_sum): 0.52895, Running average loss:0.36406, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1280, loss(cross_dice_sum): 0.17797, Running average loss:0.36119, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:41,674 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1280, loss(cross_dice_sum): 0.17797, Running average loss:0.36119, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1290, loss(cross_dice_sum): 0.28431, Running average loss:0.36988, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:43,059 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1290, loss(cross_dice_sum): 0.28431, Running average loss:0.36988, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1300, loss(cross_dice_sum): 0.15564, Running average loss:0.36555, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:44,430 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1300, loss(cross_dice_sum): 0.15564, Running average loss:0.36555, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1310, loss(cross_dice_sum): 0.23476, Running average loss:0.36538, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:45,800 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1310, loss(cross_dice_sum): 0.23476, Running average loss:0.36538, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1320, loss(cross_dice_sum): 1.78010, Running average loss:0.37144, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:47,158 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1320, loss(cross_dice_sum): 1.78010, Running average loss:0.37144, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 3/10:, Cur-Step: 1330, loss(cross_dice_sum): 0.18820, Running average loss:0.37267, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "2023-10-09 10:18:48,513 [INFO] __main__: Epoch: 3/10:, Cur-Step: 1330, loss(cross_dice_sum): 0.18820, Running average loss:0.37267, Time taken: 0:00:45.858386 ETA: 0:05:21.008701\n",
      "Epoch: 4/10:, Cur-Step: 1340, loss(cross_dice_sum): 0.14261, Running average loss:0.31594, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:18:49,933 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1340, loss(cross_dice_sum): 0.14261, Running average loss:0.31594, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1350, loss(cross_dice_sum): 0.35552, Running average loss:0.41251, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:18:51,309 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1350, loss(cross_dice_sum): 0.35552, Running average loss:0.41251, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1360, loss(cross_dice_sum): 0.53947, Running average loss:0.47315, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:18:52,693 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1360, loss(cross_dice_sum): 0.53947, Running average loss:0.47315, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1370, loss(cross_dice_sum): 0.20096, Running average loss:0.45396, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:18:54,069 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1370, loss(cross_dice_sum): 0.20096, Running average loss:0.45396, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1380, loss(cross_dice_sum): 0.13766, Running average loss:0.41631, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:18:55,437 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1380, loss(cross_dice_sum): 0.13766, Running average loss:0.41631, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1390, loss(cross_dice_sum): 0.17188, Running average loss:0.40000, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:18:56,809 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1390, loss(cross_dice_sum): 0.17188, Running average loss:0.40000, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1400, loss(cross_dice_sum): 0.21659, Running average loss:0.37004, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:18:58,195 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1400, loss(cross_dice_sum): 0.21659, Running average loss:0.37004, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1410, loss(cross_dice_sum): 0.15381, Running average loss:0.39210, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:18:59,575 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1410, loss(cross_dice_sum): 0.15381, Running average loss:0.39210, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1420, loss(cross_dice_sum): 0.24090, Running average loss:0.40050, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:00,953 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1420, loss(cross_dice_sum): 0.24090, Running average loss:0.40050, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1430, loss(cross_dice_sum): 0.27414, Running average loss:0.40282, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:02,337 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1430, loss(cross_dice_sum): 0.27414, Running average loss:0.40282, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1440, loss(cross_dice_sum): 0.19770, Running average loss:0.39495, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:03,717 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1440, loss(cross_dice_sum): 0.19770, Running average loss:0.39495, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1450, loss(cross_dice_sum): 1.77056, Running average loss:0.40094, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:05,106 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1450, loss(cross_dice_sum): 1.77056, Running average loss:0.40094, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1460, loss(cross_dice_sum): 0.18632, Running average loss:0.39291, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:06,483 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1460, loss(cross_dice_sum): 0.18632, Running average loss:0.39291, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1470, loss(cross_dice_sum): 0.17438, Running average loss:0.38928, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:07,864 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1470, loss(cross_dice_sum): 0.17438, Running average loss:0.38928, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1480, loss(cross_dice_sum): 0.41201, Running average loss:0.38703, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:09,243 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1480, loss(cross_dice_sum): 0.41201, Running average loss:0.38703, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1490, loss(cross_dice_sum): 0.20593, Running average loss:0.38854, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:10,624 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1490, loss(cross_dice_sum): 0.20593, Running average loss:0.38854, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1500, loss(cross_dice_sum): 0.25126, Running average loss:0.37789, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:12,012 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1500, loss(cross_dice_sum): 0.25126, Running average loss:0.37789, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1510, loss(cross_dice_sum): 0.31921, Running average loss:0.37204, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:13,395 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1510, loss(cross_dice_sum): 0.31921, Running average loss:0.37204, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1520, loss(cross_dice_sum): 0.14903, Running average loss:0.36492, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:14,780 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1520, loss(cross_dice_sum): 0.14903, Running average loss:0.36492, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1530, loss(cross_dice_sum): 0.14947, Running average loss:0.36457, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:16,162 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1530, loss(cross_dice_sum): 0.14947, Running average loss:0.36457, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1540, loss(cross_dice_sum): 0.25681, Running average loss:0.36865, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:17,544 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1540, loss(cross_dice_sum): 0.25681, Running average loss:0.36865, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1550, loss(cross_dice_sum): 0.76334, Running average loss:0.36677, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:18,932 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1550, loss(cross_dice_sum): 0.76334, Running average loss:0.36677, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1560, loss(cross_dice_sum): 0.60351, Running average loss:0.36580, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:20,308 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1560, loss(cross_dice_sum): 0.60351, Running average loss:0.36580, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1570, loss(cross_dice_sum): 0.44214, Running average loss:0.36274, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:21,690 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1570, loss(cross_dice_sum): 0.44214, Running average loss:0.36274, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1580, loss(cross_dice_sum): 0.47459, Running average loss:0.36086, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:23,076 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1580, loss(cross_dice_sum): 0.47459, Running average loss:0.36086, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1590, loss(cross_dice_sum): 0.13797, Running average loss:0.36461, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:24,460 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1590, loss(cross_dice_sum): 0.13797, Running average loss:0.36461, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1600, loss(cross_dice_sum): 0.68989, Running average loss:0.36272, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:25,843 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1600, loss(cross_dice_sum): 0.68989, Running average loss:0.36272, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1610, loss(cross_dice_sum): 0.42301, Running average loss:0.35771, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:27,225 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1610, loss(cross_dice_sum): 0.42301, Running average loss:0.35771, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1620, loss(cross_dice_sum): 0.25016, Running average loss:0.35878, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:28,609 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1620, loss(cross_dice_sum): 0.25016, Running average loss:0.35878, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1630, loss(cross_dice_sum): 0.76736, Running average loss:0.36101, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:29,991 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1630, loss(cross_dice_sum): 0.76736, Running average loss:0.36101, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1640, loss(cross_dice_sum): 0.77237, Running average loss:0.35956, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:31,387 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1640, loss(cross_dice_sum): 0.77237, Running average loss:0.35956, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1650, loss(cross_dice_sum): 0.79611, Running average loss:0.35761, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:32,766 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1650, loss(cross_dice_sum): 0.79611, Running average loss:0.35761, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 4/10:, Cur-Step: 1660, loss(cross_dice_sum): 0.60537, Running average loss:0.35749, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "2023-10-09 10:19:34,149 [INFO] __main__: Epoch: 4/10:, Cur-Step: 1660, loss(cross_dice_sum): 0.60537, Running average loss:0.35749, Time taken: 0:00:46.098005 ETA: 0:04:36.588029\n",
      "Epoch: 5/10:, Cur-Step: 1670, loss(cross_dice_sum): 0.17511, Running average loss:0.17511, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:35,525 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1670, loss(cross_dice_sum): 0.17511, Running average loss:0.17511, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1680, loss(cross_dice_sum): 0.46651, Running average loss:0.29268, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:36,906 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1680, loss(cross_dice_sum): 0.46651, Running average loss:0.29268, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1690, loss(cross_dice_sum): 0.27247, Running average loss:0.34228, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:38,289 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1690, loss(cross_dice_sum): 0.27247, Running average loss:0.34228, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1700, loss(cross_dice_sum): 0.59084, Running average loss:0.32164, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:39,674 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1700, loss(cross_dice_sum): 0.59084, Running average loss:0.32164, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1710, loss(cross_dice_sum): 0.21024, Running average loss:0.29739, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:41,058 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1710, loss(cross_dice_sum): 0.21024, Running average loss:0.29739, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1720, loss(cross_dice_sum): 0.18111, Running average loss:0.30266, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:42,455 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1720, loss(cross_dice_sum): 0.18111, Running average loss:0.30266, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1730, loss(cross_dice_sum): 0.25340, Running average loss:0.34396, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:43,849 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1730, loss(cross_dice_sum): 0.25340, Running average loss:0.34396, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1740, loss(cross_dice_sum): 0.44368, Running average loss:0.35254, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:45,233 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1740, loss(cross_dice_sum): 0.44368, Running average loss:0.35254, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1750, loss(cross_dice_sum): 0.14268, Running average loss:0.35358, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:46,612 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1750, loss(cross_dice_sum): 0.14268, Running average loss:0.35358, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1760, loss(cross_dice_sum): 0.27302, Running average loss:0.34558, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:47,997 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1760, loss(cross_dice_sum): 0.27302, Running average loss:0.34558, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1770, loss(cross_dice_sum): 0.15777, Running average loss:0.34808, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:49,376 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1770, loss(cross_dice_sum): 0.15777, Running average loss:0.34808, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1780, loss(cross_dice_sum): 0.36106, Running average loss:0.34760, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:50,770 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1780, loss(cross_dice_sum): 0.36106, Running average loss:0.34760, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1790, loss(cross_dice_sum): 0.88659, Running average loss:0.35653, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:52,155 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1790, loss(cross_dice_sum): 0.88659, Running average loss:0.35653, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1800, loss(cross_dice_sum): 0.36181, Running average loss:0.35332, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:53,546 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1800, loss(cross_dice_sum): 0.36181, Running average loss:0.35332, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1810, loss(cross_dice_sum): 0.17244, Running average loss:0.35329, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:54,916 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1810, loss(cross_dice_sum): 0.17244, Running average loss:0.35329, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1820, loss(cross_dice_sum): 0.19805, Running average loss:0.34562, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:56,289 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1820, loss(cross_dice_sum): 0.19805, Running average loss:0.34562, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1830, loss(cross_dice_sum): 0.13350, Running average loss:0.34132, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:57,675 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1830, loss(cross_dice_sum): 0.13350, Running average loss:0.34132, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1840, loss(cross_dice_sum): 0.14342, Running average loss:0.34091, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:19:59,056 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1840, loss(cross_dice_sum): 0.14342, Running average loss:0.34091, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1850, loss(cross_dice_sum): 0.26589, Running average loss:0.33853, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:00,460 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1850, loss(cross_dice_sum): 0.26589, Running average loss:0.33853, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1860, loss(cross_dice_sum): 0.24341, Running average loss:0.33011, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:01,850 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1860, loss(cross_dice_sum): 0.24341, Running average loss:0.33011, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1870, loss(cross_dice_sum): 0.24913, Running average loss:0.32932, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:03,234 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1870, loss(cross_dice_sum): 0.24913, Running average loss:0.32932, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1880, loss(cross_dice_sum): 0.58270, Running average loss:0.33018, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:04,626 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1880, loss(cross_dice_sum): 0.58270, Running average loss:0.33018, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1890, loss(cross_dice_sum): 0.31329, Running average loss:0.33630, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:06,007 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1890, loss(cross_dice_sum): 0.31329, Running average loss:0.33630, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1900, loss(cross_dice_sum): 0.18399, Running average loss:0.33615, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:07,399 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1900, loss(cross_dice_sum): 0.18399, Running average loss:0.33615, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1910, loss(cross_dice_sum): 0.27126, Running average loss:0.33500, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:08,783 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1910, loss(cross_dice_sum): 0.27126, Running average loss:0.33500, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1920, loss(cross_dice_sum): 0.48428, Running average loss:0.35006, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:10,177 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1920, loss(cross_dice_sum): 0.48428, Running average loss:0.35006, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1930, loss(cross_dice_sum): 0.25530, Running average loss:0.35143, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:11,560 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1930, loss(cross_dice_sum): 0.25530, Running average loss:0.35143, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1940, loss(cross_dice_sum): 0.63843, Running average loss:0.35503, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:12,950 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1940, loss(cross_dice_sum): 0.63843, Running average loss:0.35503, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1950, loss(cross_dice_sum): 0.46738, Running average loss:0.35330, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:14,334 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1950, loss(cross_dice_sum): 0.46738, Running average loss:0.35330, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1960, loss(cross_dice_sum): 0.82972, Running average loss:0.35591, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:15,714 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1960, loss(cross_dice_sum): 0.82972, Running average loss:0.35591, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1970, loss(cross_dice_sum): 0.19322, Running average loss:0.35520, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:17,099 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1970, loss(cross_dice_sum): 0.19322, Running average loss:0.35520, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1980, loss(cross_dice_sum): 1.87115, Running average loss:0.35688, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:18,484 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1980, loss(cross_dice_sum): 1.87115, Running average loss:0.35688, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 1990, loss(cross_dice_sum): 0.62634, Running average loss:0.35977, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:19,870 [INFO] __main__: Epoch: 5/10:, Cur-Step: 1990, loss(cross_dice_sum): 0.62634, Running average loss:0.35977, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 5/10:, Cur-Step: 2000, loss(cross_dice_sum): 0.22750, Running average loss:0.35606, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "2023-10-09 10:20:21,245 [INFO] __main__: Epoch: 5/10:, Cur-Step: 2000, loss(cross_dice_sum): 0.22750, Running average loss:0.35606, Time taken: 0:00:46.328935 ETA: 0:03:51.644676\n",
      "Epoch: 6/10:, Cur-Step: 2010, loss(cross_dice_sum): 0.64531, Running average loss:0.32607, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:22,652 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2010, loss(cross_dice_sum): 0.64531, Running average loss:0.32607, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2020, loss(cross_dice_sum): 0.21654, Running average loss:0.34166, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:24,042 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2020, loss(cross_dice_sum): 0.21654, Running average loss:0.34166, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2030, loss(cross_dice_sum): 0.21278, Running average loss:0.31007, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:25,427 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2030, loss(cross_dice_sum): 0.21278, Running average loss:0.31007, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2040, loss(cross_dice_sum): 0.19431, Running average loss:0.32189, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:26,818 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2040, loss(cross_dice_sum): 0.19431, Running average loss:0.32189, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2050, loss(cross_dice_sum): 0.14491, Running average loss:0.29750, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:28,212 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2050, loss(cross_dice_sum): 0.14491, Running average loss:0.29750, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2060, loss(cross_dice_sum): 0.26215, Running average loss:0.28173, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:29,603 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2060, loss(cross_dice_sum): 0.26215, Running average loss:0.28173, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2070, loss(cross_dice_sum): 0.12403, Running average loss:0.28340, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:30,990 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2070, loss(cross_dice_sum): 0.12403, Running average loss:0.28340, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2080, loss(cross_dice_sum): 0.49687, Running average loss:0.28589, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:32,384 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2080, loss(cross_dice_sum): 0.49687, Running average loss:0.28589, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2090, loss(cross_dice_sum): 0.21567, Running average loss:0.29037, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:33,766 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2090, loss(cross_dice_sum): 0.21567, Running average loss:0.29037, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2100, loss(cross_dice_sum): 0.34399, Running average loss:0.28935, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:35,153 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2100, loss(cross_dice_sum): 0.34399, Running average loss:0.28935, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2110, loss(cross_dice_sum): 0.63689, Running average loss:0.28669, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:36,548 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2110, loss(cross_dice_sum): 0.63689, Running average loss:0.28669, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2120, loss(cross_dice_sum): 0.56847, Running average loss:0.29299, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:37,932 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2120, loss(cross_dice_sum): 0.56847, Running average loss:0.29299, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2130, loss(cross_dice_sum): 0.14634, Running average loss:0.29061, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:39,326 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2130, loss(cross_dice_sum): 0.14634, Running average loss:0.29061, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2140, loss(cross_dice_sum): 0.22098, Running average loss:0.29018, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:40,719 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2140, loss(cross_dice_sum): 0.22098, Running average loss:0.29018, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2150, loss(cross_dice_sum): 0.28351, Running average loss:0.29025, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:42,103 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2150, loss(cross_dice_sum): 0.28351, Running average loss:0.29025, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2160, loss(cross_dice_sum): 0.67561, Running average loss:0.30918, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:43,498 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2160, loss(cross_dice_sum): 0.67561, Running average loss:0.30918, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2170, loss(cross_dice_sum): 0.21220, Running average loss:0.30482, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:44,889 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2170, loss(cross_dice_sum): 0.21220, Running average loss:0.30482, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2180, loss(cross_dice_sum): 0.20070, Running average loss:0.30948, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:46,277 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2180, loss(cross_dice_sum): 0.20070, Running average loss:0.30948, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2190, loss(cross_dice_sum): 0.14252, Running average loss:0.31767, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:47,670 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2190, loss(cross_dice_sum): 0.14252, Running average loss:0.31767, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2200, loss(cross_dice_sum): 0.25440, Running average loss:0.32191, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:49,055 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2200, loss(cross_dice_sum): 0.25440, Running average loss:0.32191, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2210, loss(cross_dice_sum): 0.50257, Running average loss:0.32699, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:50,446 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2210, loss(cross_dice_sum): 0.50257, Running average loss:0.32699, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2220, loss(cross_dice_sum): 0.97821, Running average loss:0.33090, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:51,829 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2220, loss(cross_dice_sum): 0.97821, Running average loss:0.33090, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2230, loss(cross_dice_sum): 0.18705, Running average loss:0.33030, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:53,213 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2230, loss(cross_dice_sum): 0.18705, Running average loss:0.33030, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2240, loss(cross_dice_sum): 0.13710, Running average loss:0.33995, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:54,585 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2240, loss(cross_dice_sum): 0.13710, Running average loss:0.33995, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2250, loss(cross_dice_sum): 0.42546, Running average loss:0.33824, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:55,958 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2250, loss(cross_dice_sum): 0.42546, Running average loss:0.33824, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2260, loss(cross_dice_sum): 0.29439, Running average loss:0.33226, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:57,337 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2260, loss(cross_dice_sum): 0.29439, Running average loss:0.33226, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2270, loss(cross_dice_sum): 0.42511, Running average loss:0.33130, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:20:58,726 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2270, loss(cross_dice_sum): 0.42511, Running average loss:0.33130, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2280, loss(cross_dice_sum): 0.15025, Running average loss:0.32999, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:21:00,108 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2280, loss(cross_dice_sum): 0.15025, Running average loss:0.32999, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2290, loss(cross_dice_sum): 0.12857, Running average loss:0.32964, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:21:01,488 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2290, loss(cross_dice_sum): 0.12857, Running average loss:0.32964, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2300, loss(cross_dice_sum): 0.45757, Running average loss:0.33485, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:21:02,871 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2300, loss(cross_dice_sum): 0.45757, Running average loss:0.33485, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2310, loss(cross_dice_sum): 1.81260, Running average loss:0.33952, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:21:04,258 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2310, loss(cross_dice_sum): 1.81260, Running average loss:0.33952, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2320, loss(cross_dice_sum): 0.25197, Running average loss:0.34372, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:21:05,646 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2320, loss(cross_dice_sum): 0.25197, Running average loss:0.34372, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 6/10:, Cur-Step: 2330, loss(cross_dice_sum): 0.40006, Running average loss:0.34381, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "2023-10-09 10:21:07,027 [INFO] __main__: Epoch: 6/10:, Cur-Step: 2330, loss(cross_dice_sum): 0.40006, Running average loss:0.34381, Time taken: 0:00:46.418632 ETA: 0:03:05.674529\n",
      "Epoch: 7/10:, Cur-Step: 2340, loss(cross_dice_sum): 0.30006, Running average loss:0.27219, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:08,415 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2340, loss(cross_dice_sum): 0.30006, Running average loss:0.27219, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2350, loss(cross_dice_sum): 0.34650, Running average loss:0.29746, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:09,810 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2350, loss(cross_dice_sum): 0.34650, Running average loss:0.29746, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2360, loss(cross_dice_sum): 0.15072, Running average loss:0.42166, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:11,200 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2360, loss(cross_dice_sum): 0.15072, Running average loss:0.42166, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2370, loss(cross_dice_sum): 0.19435, Running average loss:0.36692, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:12,591 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2370, loss(cross_dice_sum): 0.19435, Running average loss:0.36692, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2380, loss(cross_dice_sum): 0.14166, Running average loss:0.37317, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:13,974 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2380, loss(cross_dice_sum): 0.14166, Running average loss:0.37317, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2390, loss(cross_dice_sum): 0.18588, Running average loss:0.35343, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:15,362 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2390, loss(cross_dice_sum): 0.18588, Running average loss:0.35343, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2400, loss(cross_dice_sum): 0.27981, Running average loss:0.34823, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:16,747 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2400, loss(cross_dice_sum): 0.27981, Running average loss:0.34823, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2410, loss(cross_dice_sum): 0.17447, Running average loss:0.33520, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:18,122 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2410, loss(cross_dice_sum): 0.17447, Running average loss:0.33520, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2420, loss(cross_dice_sum): 0.47825, Running average loss:0.32390, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:19,506 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2420, loss(cross_dice_sum): 0.47825, Running average loss:0.32390, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2430, loss(cross_dice_sum): 3.01244, Running average loss:0.34376, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:20,895 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2430, loss(cross_dice_sum): 3.01244, Running average loss:0.34376, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2440, loss(cross_dice_sum): 0.24863, Running average loss:0.35007, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:22,277 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2440, loss(cross_dice_sum): 0.24863, Running average loss:0.35007, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2450, loss(cross_dice_sum): 0.22052, Running average loss:0.34883, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:23,664 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2450, loss(cross_dice_sum): 0.22052, Running average loss:0.34883, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2460, loss(cross_dice_sum): 0.58348, Running average loss:0.34955, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:25,043 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2460, loss(cross_dice_sum): 0.58348, Running average loss:0.34955, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2470, loss(cross_dice_sum): 0.27339, Running average loss:0.34838, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:26,433 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2470, loss(cross_dice_sum): 0.27339, Running average loss:0.34838, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2480, loss(cross_dice_sum): 0.23343, Running average loss:0.34312, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:27,818 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2480, loss(cross_dice_sum): 0.23343, Running average loss:0.34312, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2490, loss(cross_dice_sum): 0.14271, Running average loss:0.33714, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:29,204 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2490, loss(cross_dice_sum): 0.14271, Running average loss:0.33714, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2500, loss(cross_dice_sum): 0.15570, Running average loss:0.35087, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:30,588 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2500, loss(cross_dice_sum): 0.15570, Running average loss:0.35087, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2510, loss(cross_dice_sum): 0.16961, Running average loss:0.35029, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:31,977 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2510, loss(cross_dice_sum): 0.16961, Running average loss:0.35029, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2520, loss(cross_dice_sum): 0.22473, Running average loss:0.35365, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:33,357 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2520, loss(cross_dice_sum): 0.22473, Running average loss:0.35365, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2530, loss(cross_dice_sum): 0.12398, Running average loss:0.35278, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:34,734 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2530, loss(cross_dice_sum): 0.12398, Running average loss:0.35278, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2540, loss(cross_dice_sum): 0.29388, Running average loss:0.35228, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:36,114 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2540, loss(cross_dice_sum): 0.29388, Running average loss:0.35228, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2550, loss(cross_dice_sum): 0.22795, Running average loss:0.34920, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:37,492 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2550, loss(cross_dice_sum): 0.22795, Running average loss:0.34920, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2560, loss(cross_dice_sum): 0.43776, Running average loss:0.34453, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:38,878 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2560, loss(cross_dice_sum): 0.43776, Running average loss:0.34453, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2570, loss(cross_dice_sum): 0.13592, Running average loss:0.33976, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:40,252 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2570, loss(cross_dice_sum): 0.13592, Running average loss:0.33976, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2580, loss(cross_dice_sum): 0.14473, Running average loss:0.33229, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:41,629 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2580, loss(cross_dice_sum): 0.14473, Running average loss:0.33229, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2590, loss(cross_dice_sum): 0.16016, Running average loss:0.33730, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:43,011 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2590, loss(cross_dice_sum): 0.16016, Running average loss:0.33730, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2600, loss(cross_dice_sum): 0.41010, Running average loss:0.33865, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:44,390 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2600, loss(cross_dice_sum): 0.41010, Running average loss:0.33865, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2610, loss(cross_dice_sum): 0.53908, Running average loss:0.33968, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:45,766 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2610, loss(cross_dice_sum): 0.53908, Running average loss:0.33968, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2620, loss(cross_dice_sum): 0.53408, Running average loss:0.33485, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:47,150 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2620, loss(cross_dice_sum): 0.53408, Running average loss:0.33485, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2630, loss(cross_dice_sum): 0.12115, Running average loss:0.33426, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:48,529 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2630, loss(cross_dice_sum): 0.12115, Running average loss:0.33426, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2640, loss(cross_dice_sum): 0.12504, Running average loss:0.33659, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:49,901 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2640, loss(cross_dice_sum): 0.12504, Running average loss:0.33659, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2650, loss(cross_dice_sum): 0.97253, Running average loss:0.33776, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:51,270 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2650, loss(cross_dice_sum): 0.97253, Running average loss:0.33776, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2660, loss(cross_dice_sum): 0.51797, Running average loss:0.33665, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:52,631 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2660, loss(cross_dice_sum): 0.51797, Running average loss:0.33665, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 7/10:, Cur-Step: 2670, loss(cross_dice_sum): 0.35234, Running average loss:0.33534, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "2023-10-09 10:21:53,994 [INFO] __main__: Epoch: 7/10:, Cur-Step: 2670, loss(cross_dice_sum): 0.35234, Running average loss:0.33534, Time taken: 0:00:46.464464 ETA: 0:02:19.393393\n",
      "Epoch: 8/10:, Cur-Step: 2680, loss(cross_dice_sum): 0.12158, Running average loss:0.33460, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:21:55,388 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2680, loss(cross_dice_sum): 0.12158, Running average loss:0.33460, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2690, loss(cross_dice_sum): 0.21854, Running average loss:0.38435, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:21:56,769 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2690, loss(cross_dice_sum): 0.21854, Running average loss:0.38435, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2700, loss(cross_dice_sum): 0.39920, Running average loss:0.41165, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:21:58,142 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2700, loss(cross_dice_sum): 0.39920, Running average loss:0.41165, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2710, loss(cross_dice_sum): 0.18194, Running average loss:0.38281, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:21:59,528 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2710, loss(cross_dice_sum): 0.18194, Running average loss:0.38281, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2720, loss(cross_dice_sum): 0.13620, Running average loss:0.36259, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:00,916 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2720, loss(cross_dice_sum): 0.13620, Running average loss:0.36259, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2730, loss(cross_dice_sum): 0.13680, Running average loss:0.35776, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:02,290 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2730, loss(cross_dice_sum): 0.13680, Running average loss:0.35776, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2740, loss(cross_dice_sum): 0.20843, Running average loss:0.34502, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:03,675 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2740, loss(cross_dice_sum): 0.20843, Running average loss:0.34502, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2750, loss(cross_dice_sum): 0.11290, Running average loss:0.33657, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:05,052 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2750, loss(cross_dice_sum): 0.11290, Running average loss:0.33657, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2760, loss(cross_dice_sum): 0.18736, Running average loss:0.32752, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:06,429 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2760, loss(cross_dice_sum): 0.18736, Running average loss:0.32752, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2770, loss(cross_dice_sum): 0.24792, Running average loss:0.34297, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:07,807 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2770, loss(cross_dice_sum): 0.24792, Running average loss:0.34297, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2780, loss(cross_dice_sum): 0.17495, Running average loss:0.33981, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:09,196 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2780, loss(cross_dice_sum): 0.17495, Running average loss:0.33981, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2790, loss(cross_dice_sum): 0.16430, Running average loss:0.34306, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:10,576 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2790, loss(cross_dice_sum): 0.16430, Running average loss:0.34306, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2800, loss(cross_dice_sum): 0.29607, Running average loss:0.34187, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:11,961 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2800, loss(cross_dice_sum): 0.29607, Running average loss:0.34187, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2810, loss(cross_dice_sum): 0.11900, Running average loss:0.33311, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:13,349 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2810, loss(cross_dice_sum): 0.11900, Running average loss:0.33311, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2820, loss(cross_dice_sum): 0.12777, Running average loss:0.32631, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:14,734 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2820, loss(cross_dice_sum): 0.12777, Running average loss:0.32631, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2830, loss(cross_dice_sum): 0.14152, Running average loss:0.32100, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:16,110 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2830, loss(cross_dice_sum): 0.14152, Running average loss:0.32100, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2840, loss(cross_dice_sum): 0.14093, Running average loss:0.31443, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:17,488 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2840, loss(cross_dice_sum): 0.14093, Running average loss:0.31443, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2850, loss(cross_dice_sum): 0.19809, Running average loss:0.30774, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:18,882 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2850, loss(cross_dice_sum): 0.19809, Running average loss:0.30774, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2860, loss(cross_dice_sum): 0.20560, Running average loss:0.31023, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:20,259 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2860, loss(cross_dice_sum): 0.20560, Running average loss:0.31023, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2870, loss(cross_dice_sum): 0.26572, Running average loss:0.31150, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:21,641 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2870, loss(cross_dice_sum): 0.26572, Running average loss:0.31150, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2880, loss(cross_dice_sum): 0.28833, Running average loss:0.30962, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:23,033 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2880, loss(cross_dice_sum): 0.28833, Running average loss:0.30962, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2890, loss(cross_dice_sum): 0.28110, Running average loss:0.31844, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:24,417 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2890, loss(cross_dice_sum): 0.28110, Running average loss:0.31844, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2900, loss(cross_dice_sum): 0.18711, Running average loss:0.32187, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:25,808 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2900, loss(cross_dice_sum): 0.18711, Running average loss:0.32187, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2910, loss(cross_dice_sum): 0.57929, Running average loss:0.32493, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:27,202 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2910, loss(cross_dice_sum): 0.57929, Running average loss:0.32493, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2920, loss(cross_dice_sum): 1.25224, Running average loss:0.32724, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:28,588 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2920, loss(cross_dice_sum): 1.25224, Running average loss:0.32724, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2930, loss(cross_dice_sum): 0.38498, Running average loss:0.32498, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:29,977 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2930, loss(cross_dice_sum): 0.38498, Running average loss:0.32498, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2940, loss(cross_dice_sum): 0.22447, Running average loss:0.32522, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:31,355 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2940, loss(cross_dice_sum): 0.22447, Running average loss:0.32522, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2950, loss(cross_dice_sum): 0.58640, Running average loss:0.33001, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:32,741 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2950, loss(cross_dice_sum): 0.58640, Running average loss:0.33001, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2960, loss(cross_dice_sum): 0.33133, Running average loss:0.32797, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:34,142 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2960, loss(cross_dice_sum): 0.33133, Running average loss:0.32797, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2970, loss(cross_dice_sum): 0.11736, Running average loss:0.32594, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:35,538 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2970, loss(cross_dice_sum): 0.11736, Running average loss:0.32594, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2980, loss(cross_dice_sum): 0.25728, Running average loss:0.32322, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:36,910 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2980, loss(cross_dice_sum): 0.25728, Running average loss:0.32322, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 2990, loss(cross_dice_sum): 0.14305, Running average loss:0.32346, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:38,282 [INFO] __main__: Epoch: 8/10:, Cur-Step: 2990, loss(cross_dice_sum): 0.14305, Running average loss:0.32346, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 8/10:, Cur-Step: 3000, loss(cross_dice_sum): 0.20929, Running average loss:0.32217, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "2023-10-09 10:22:39,651 [INFO] __main__: Epoch: 8/10:, Cur-Step: 3000, loss(cross_dice_sum): 0.20929, Running average loss:0.32217, Time taken: 0:00:46.287539 ETA: 0:01:32.575078\n",
      "Epoch: 9/10:, Cur-Step: 3010, loss(cross_dice_sum): 0.48967, Running average loss:0.37461, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:41,061 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3010, loss(cross_dice_sum): 0.48967, Running average loss:0.37461, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3020, loss(cross_dice_sum): 0.17669, Running average loss:0.33165, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:42,445 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3020, loss(cross_dice_sum): 0.17669, Running average loss:0.33165, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3030, loss(cross_dice_sum): 0.11436, Running average loss:0.35206, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:43,832 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3030, loss(cross_dice_sum): 0.11436, Running average loss:0.35206, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3040, loss(cross_dice_sum): 0.46721, Running average loss:0.32554, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:45,216 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3040, loss(cross_dice_sum): 0.46721, Running average loss:0.32554, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3050, loss(cross_dice_sum): 0.16735, Running average loss:0.36168, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:46,595 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3050, loss(cross_dice_sum): 0.16735, Running average loss:0.36168, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3060, loss(cross_dice_sum): 0.22688, Running average loss:0.34955, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:47,985 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3060, loss(cross_dice_sum): 0.22688, Running average loss:0.34955, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3070, loss(cross_dice_sum): 0.23867, Running average loss:0.34055, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:49,374 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3070, loss(cross_dice_sum): 0.23867, Running average loss:0.34055, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3080, loss(cross_dice_sum): 0.12987, Running average loss:0.32154, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:50,765 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3080, loss(cross_dice_sum): 0.12987, Running average loss:0.32154, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3090, loss(cross_dice_sum): 0.47250, Running average loss:0.31616, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:52,144 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3090, loss(cross_dice_sum): 0.47250, Running average loss:0.31616, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3100, loss(cross_dice_sum): 0.31691, Running average loss:0.32438, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:53,541 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3100, loss(cross_dice_sum): 0.31691, Running average loss:0.32438, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3110, loss(cross_dice_sum): 0.24627, Running average loss:0.32673, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:54,904 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3110, loss(cross_dice_sum): 0.24627, Running average loss:0.32673, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3120, loss(cross_dice_sum): 0.24990, Running average loss:0.33900, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:56,280 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3120, loss(cross_dice_sum): 0.24990, Running average loss:0.33900, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3130, loss(cross_dice_sum): 0.14990, Running average loss:0.33001, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:57,660 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3130, loss(cross_dice_sum): 0.14990, Running average loss:0.33001, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3140, loss(cross_dice_sum): 0.63944, Running average loss:0.34087, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:22:59,051 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3140, loss(cross_dice_sum): 0.63944, Running average loss:0.34087, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3150, loss(cross_dice_sum): 0.42793, Running average loss:0.33617, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:00,447 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3150, loss(cross_dice_sum): 0.42793, Running average loss:0.33617, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3160, loss(cross_dice_sum): 0.41139, Running average loss:0.32743, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:01,841 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3160, loss(cross_dice_sum): 0.41139, Running average loss:0.32743, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3170, loss(cross_dice_sum): 0.10996, Running average loss:0.32641, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:03,236 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3170, loss(cross_dice_sum): 0.10996, Running average loss:0.32641, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3180, loss(cross_dice_sum): 0.13528, Running average loss:0.32631, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:04,618 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3180, loss(cross_dice_sum): 0.13528, Running average loss:0.32631, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3190, loss(cross_dice_sum): 0.12244, Running average loss:0.31985, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:05,996 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3190, loss(cross_dice_sum): 0.12244, Running average loss:0.31985, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3200, loss(cross_dice_sum): 0.28943, Running average loss:0.33206, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:07,377 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3200, loss(cross_dice_sum): 0.28943, Running average loss:0.33206, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3210, loss(cross_dice_sum): 0.17795, Running average loss:0.32964, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:08,751 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3210, loss(cross_dice_sum): 0.17795, Running average loss:0.32964, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3220, loss(cross_dice_sum): 0.39568, Running average loss:0.32733, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:10,132 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3220, loss(cross_dice_sum): 0.39568, Running average loss:0.32733, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3230, loss(cross_dice_sum): 0.13869, Running average loss:0.32763, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:11,523 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3230, loss(cross_dice_sum): 0.13869, Running average loss:0.32763, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3240, loss(cross_dice_sum): 0.18628, Running average loss:0.32430, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:12,904 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3240, loss(cross_dice_sum): 0.18628, Running average loss:0.32430, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3250, loss(cross_dice_sum): 0.40529, Running average loss:0.31983, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:14,291 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3250, loss(cross_dice_sum): 0.40529, Running average loss:0.31983, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3260, loss(cross_dice_sum): 0.72177, Running average loss:0.32245, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:15,675 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3260, loss(cross_dice_sum): 0.72177, Running average loss:0.32245, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3270, loss(cross_dice_sum): 1.06492, Running average loss:0.32341, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:17,056 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3270, loss(cross_dice_sum): 1.06492, Running average loss:0.32341, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3280, loss(cross_dice_sum): 0.22989, Running average loss:0.32037, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:18,439 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3280, loss(cross_dice_sum): 0.22989, Running average loss:0.32037, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3290, loss(cross_dice_sum): 0.19913, Running average loss:0.32467, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:19,821 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3290, loss(cross_dice_sum): 0.19913, Running average loss:0.32467, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3300, loss(cross_dice_sum): 0.39233, Running average loss:0.32631, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:21,206 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3300, loss(cross_dice_sum): 0.39233, Running average loss:0.32631, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3310, loss(cross_dice_sum): 0.12896, Running average loss:0.32608, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:22,589 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3310, loss(cross_dice_sum): 0.12896, Running average loss:0.32608, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3320, loss(cross_dice_sum): 0.15609, Running average loss:0.32604, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:23,968 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3320, loss(cross_dice_sum): 0.15609, Running average loss:0.32604, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "Epoch: 9/10:, Cur-Step: 3330, loss(cross_dice_sum): 0.33562, Running average loss:0.32491, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "2023-10-09 10:23:25,343 [INFO] __main__: Epoch: 9/10:, Cur-Step: 3330, loss(cross_dice_sum): 0.33562, Running average loss:0.32491, Time taken: 0:00:46.366273 ETA: 0:00:46.366273\n",
      "INFO:tensorflow:Saving checkpoints for step-3340.\n",
      "2023-10-09 10:23:26,605 [INFO] tensorflow: Saving checkpoints for step-3340.\n",
      "Throughput Avg: 7.286 img/s\n",
      "Latency Avg: 139.575 ms\n",
      "Latency 90%: 143.029 ms\n",
      "Latency 95%: 143.69 ms\n",
      "Latency 99%: 144.983 ms\n",
      "DLL 2023-10-09 10:23:31.197201 - () throughput_train:7.285887411859308  latency_train:139.57477108594648 elapsed_time:505.505791\n",
      "INFO:tensorflow:Loss for final step: 0.10930104.\n",
      "2023-10-09 10:23:31,367 [INFO] tensorflow: Loss for final step: 0.10930104.\n",
      "Saving the final step model to /workspace/tao-experiments/unet/resnet18/weights/resnet18.tlt\n",
      "2023-10-09 10:23:31,368 [INFO] __main__: Saving the final step model to /workspace/tao-experiments/unet/resnet18/weights/resnet18.tlt\n",
      "2023-10-09 10:23:33,396 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# train model\n",
    "!tao unet train -e $TAO_SPECS_DIR/resnet18/combined_config.txt \\\n",
    "                -r $TAO_EXPERIMENT_DIR/resnet18 \\\n",
    "                -n resnet18 \\\n",
    "                -m $TAO_EXPERIMENT_DIR/pretrained_resnet18/pretrained_semantic_segmentation_vresnet18/resnet_18.hdf5 \\\n",
    "                -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad44218-d756-4e76-883f-0fcc76044254",
   "metadata": {},
   "source": [
    "**Note**: The training may take hours to complete. `unet` supports restarting from checkpoints in case the training job is killed prematurely. Training from the closest checkpoint may be resumed by simply re-running the **same** command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72ac48b2-d38e-482c-bb73-df6439dbc166",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for every epoch at checkpoint_interval mentioned in the spec file:\n",
      "---------------------\n",
      "\u001b[01;34m/dli/task/tao_project/unet/resnet18\u001b[00m\n",
      "├── events.out.tfevents.1696846511.7658f1033c54\n",
      "├── experiment_spec.txt\n",
      "├── graph.pbtxt\n",
      "├── model.step-0.tlt\n",
      "├── model.step-3340.tlt\n",
      "├── monitor.json\n",
      "├── output.log\n",
      "├── profile_log.txt\n",
      "├── target_class_id_mapping.json\n",
      "└── \u001b[01;34mweights\u001b[00m\n",
      "    └── resnet18.tlt\n",
      "\n",
      "1 directory, 10 files\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "print('Model for every epoch at checkpoint_interval mentioned in the spec file:')\n",
    "print('---------------------')\n",
    "!tree -a $LOCAL_EXPERIMENT_DIR/resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc293375-1728-49ef-a331-a7d949ee6229",
   "metadata": {},
   "source": [
    "<a name='s2-2.7'></a>\n",
    "### Evaluating the Model ###\n",
    "The model should be evaluated for its performance at the end of training. The last step model saved in the `$USER_EXPERIMENT_DIR/resnet18/weights` directory is used for evaluation, inference, and export. The evaluation metrics include **precision**, **recall**, **f1-score**, and **IOU** for every class. The evaluation also creates `results_tlt.json` as a record. We can evaluate the model with the `evaluate` subtask. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fefc75a1-ce72-4f4f-9f78-ef8035bbbe03",
   "metadata": {},
   "source": [
    "tao unet evaluate [-h] -e <EXPERIMENT_SPEC_FILE>\n",
    "                       -m <MODEL_PATH>\n",
    "                       -o <OUTPUT_DIR>\n",
    "                       -k <KEY>\n",
    "                       [--gpus GPUS]\n",
    "                       [--gpu_index GPU_INDEX]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9d887-c398-4a6d-8c5a-e2e5629782a7",
   "metadata": {},
   "source": [
    "The `evaluate` subtask runs evaluation on the same validation set that was used during training. We can also run evaluation on an earlier model by editing the spec file to point to the intended model. When using the `evaluate` subtask, the `-e` argument indicates the path to the spec file, the `-m` argument indicates the path to the model, the `-o` argument indicates where the evaluation metrics outputs should be written, and the `-k` argument indicates the key to _load_ the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb363405-9ef2-4358-ac31-d80c692c2c8e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 10:27:10,959 [INFO] root: Registry: ['nvcr.io']\n",
      "2023-10-09 10:27:11,090 [INFO] tlt.components.instance_handler.local_instance: Running command in container: nvcr.io/nvidia/tao/tao-toolkit-tf:v3.21.11-tf1.15.5-py3\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/scripts/evaluate.py:43: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/scripts/evaluate.py:43: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2023-10-09 10:27:15,990 [INFO] __main__: Loading experiment spec at /workspace/tao-experiments/spec_files/resnet18/combined_config.txt.\n",
      "2023-10-09 10:27:15,991 [INFO] iva.unet.spec_handler.spec_loader: Merging specification from /workspace/tao-experiments/spec_files/resnet18/combined_config.txt\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2023-10-09 10:27:15,992 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2023-10-09 10:27:16,005 [INFO] iva.unet.model.utilities: Label Id 0: Train Id 0\n",
      "2023-10-09 10:27:16,006 [INFO] iva.unet.model.utilities: Label Id 255: Train Id 1\n",
      "\n",
      "Phase val: Total 112 files.\n",
      "2023-10-09 10:27:16,023 [INFO] iva.unet.model.model_io: Loading weights from /workspace/tao-experiments/unet/resnet18/weights/resnet18.tlt\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/workspace/tao-experiments/unet/resnet18/weights', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6d41667f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "2023-10-09 10:27:19,947 [INFO] tensorflow: Using config: {'_model_dir': '/workspace/tao-experiments/unet/resnet18/weights', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6d41667f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Starting Evaluation.\n",
      "0it [00:00, ?it/s]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2023-10-09 10:27:20,279 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,314 [WARNING] tensorflow: Entity <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6d4102840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6d4102840>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,326 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6d4102840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6d4102840>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "2023-10-09 10:27:20,328 [WARNING] tensorflow: \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "/opt/nvidia/third_party/keras/tensorflow_backend.py:356: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
      "  self, _map_func_set_random_wrapper, num_parallel_calls=num_parallel_calls\n",
      "WARNING:tensorflow:Entity <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,336 [WARNING] tensorflow: Entity <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,342 [WARNING] tensorflow: Entity <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,348 [WARNING] tensorflow: Entity <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/utils/data_loader.py:451: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "2023-10-09 10:27:20,348 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/utils/data_loader.py:451: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0750d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0750d0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,357 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0750d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0750d0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0757b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0757b8>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,365 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0757b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0757b8>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,370 [WARNING] tensorflow: Entity <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fb6d496c470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc075f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc075f28>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,376 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc075f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc075f28>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0ba158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0ba158>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:27:20,385 [WARNING] tensorflow: Entity <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0ba158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.input_fn_aigs_tf.<locals>.<lambda> at 0x7fb6cc0ba158>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "2023-10-09 10:27:20,395 [INFO] tensorflow: Calling model_fn.\n",
      "2023-10-09 10:27:20,395 [INFO] iva.unet.utils.model_fn: {'exec_mode': 'train', 'model_dir': '/workspace/tao-experiments/unet/resnet18/weights', 'resize_padding': False, 'resize_method': 'BILINEAR', 'log_dir': None, 'batch_size': 1, 'learning_rate': 9.999999747378752e-05, 'activation': 'softmax', 'crossvalidation_idx': None, 'max_steps': None, 'regularizer_type': 2, 'weight_decay': 1.9999999494757503e-05, 'log_summary_steps': 10, 'warmup_steps': 0, 'augment': True, 'use_amp': False, 'use_trt': False, 'use_xla': False, 'loss': 'cross_dice_sum', 'epochs': 10, 'pretrained_weights_file': None, 'lr_scheduler': None, 'unet_model': <iva.unet.model.resnet_unet.ResnetUnet object at 0x7fb6d40a8860>, 'key': 'my_model_key', 'experiment_spec': dataset_config {\n",
      "  augment: true\n",
      "  dataset: \"custom\"\n",
      "  input_image_type: \"color\"\n",
      "  train_images_path: \"/workspace/tao-experiments/data/images/train\"\n",
      "  train_masks_path: \"/workspace/tao-experiments/data/masks/train\"\n",
      "  val_images_path: \"/workspace/tao-experiments/data/images/val\"\n",
      "  val_masks_path: \"/workspace/tao-experiments/data/masks/val\"\n",
      "  test_images_path: \"/workspace/tao-experiments/data/images/val\"\n",
      "  data_class_config {\n",
      "    target_classes {\n",
      "      name: \"notflood\"\n",
      "      mapping_class: \"notflood\"\n",
      "    }\n",
      "    target_classes {\n",
      "      name: \"flood\"\n",
      "      label_id: 255\n",
      "      mapping_class: \"flood\"\n",
      "    }\n",
      "  }\n",
      "  augmentation_config {\n",
      "    spatial_augmentation {\n",
      "      hflip_probability: 0.5\n",
      "      vflip_probability: 0.5\n",
      "      crop_and_resize_prob: 0.5\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_config {\n",
      "  num_layers: 18\n",
      "  use_batch_norm: true\n",
      "  training_precision {\n",
      "    backend_floatx: FLOAT32\n",
      "  }\n",
      "  arch: \"resnet\"\n",
      "  all_projections: true\n",
      "  model_input_height: 512\n",
      "  model_input_width: 512\n",
      "  model_input_channels: 3\n",
      "}\n",
      "training_config {\n",
      "  batch_size: 1\n",
      "  regularizer {\n",
      "    type: L2\n",
      "    weight: 1.9999999494757503e-05\n",
      "  }\n",
      "  optimizer {\n",
      "    adam {\n",
      "      epsilon: 9.99999993922529e-09\n",
      "      beta1: 0.8999999761581421\n",
      "      beta2: 0.9990000128746033\n",
      "    }\n",
      "  }\n",
      "  checkpoint_interval: 10\n",
      "  log_summary_steps: 10\n",
      "  learning_rate: 9.999999747378752e-05\n",
      "  loss: \"cross_dice_sum\"\n",
      "  epochs: 10\n",
      "}\n",
      ", 'seed': 0, 'benchmark': False, 'temp_dir': '/tmp/tmpc773wnjn', 'num_classes': 2, 'num_conf_mat_classes': 2, 'start_step': 0, 'checkpoint_interval': 10, 'model_json': None, 'load_graph': False, 'weights_monitor': False, 'phase': 'val'}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2023-10-09 10:27:20,396 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2023-10-09 10:27:20,396 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2023-10-09 10:27:20,409 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2023-10-09 10:27:20,413 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 512, 512)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 256, 256) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 256, 256) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 256, 256) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 128, 128) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 128, 128) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 128, 128) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 128, 128) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 128, 128) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 128, 128) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 128, 128) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 128, 128) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 128, 128) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 128, 128) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 128, 128) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 128, 128) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 128, 128) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 128, 128) 4160        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 128, 128) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 128, 128) 256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 128, 128) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 128, 128) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 64, 64)  73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 64, 64)  512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 64, 64)  0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 64, 64)  147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 64, 64)  8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 64, 64)  512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 64, 64)  512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 64, 64)  0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 64, 64)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 64, 64)  147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 64, 64)  512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 64, 64)  0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 64, 64)  147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 64, 64)  16512       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 64, 64)  512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 64, 64)  512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 64, 64)  0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 64, 64)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 32, 32)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 32, 32)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 32, 32)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 32, 32)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 32, 32)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 32, 32)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 32, 32)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 32, 32)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 32, 32)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 32, 32)  590080      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 32, 32)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 32, 32)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 32, 32)  590080      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 32, 32)  65792       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 32, 32)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 32, 32)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 32, 32)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 32, 32)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 32, 32)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 32, 32)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 32, 32)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 32, 32)  2359808     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 32, 32)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 32, 32)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 32, 32)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 32, 32)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 32, 32)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 32, 32)  2359808     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 32, 32)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 32, 32)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 32, 32)  2359808     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_shortcut (Conv2D) (None, 512, 32, 32)  262656      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 32, 32)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_shortcut (BatchNorm (None, 512, 32, 32)  2048        block_4b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 32, 32)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 32, 32)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 64, 64)  2097408     block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384, 64, 64)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 384, 64, 64)  1536        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 384, 64, 64)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 64, 64)  884992      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 64, 64)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 64, 64)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 524416      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192, 128, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 192, 128, 128 768         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 192, 128, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 221312      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 256, 256) 131136      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 256, 256 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 256, 256 512         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 256, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 256, 256) 73792       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 256, 256) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 256, 256) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 512, 512) 65600       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 512, 512) 256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 512, 512) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 512, 512) 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 512, 512) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 512, 512) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 2, 512, 512)  1154        activation_9[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 15,590,146\n",
      "Trainable params: 15,575,938\n",
      "Non-trainable params: 14,208\n",
      "__________________________________________________________________________________________________\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "2023-10-09 10:27:21,891 [INFO] tensorflow: Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2023-10-09 10:27:22,148 [INFO] tensorflow: Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpbtnr57au/model.ckpt-3340\n",
      "2023-10-09 10:27:22,525 [INFO] tensorflow: Restoring parameters from /tmp/tmpbtnr57au/model.ckpt-3340\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "2023-10-09 10:27:22,941 [INFO] tensorflow: Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "2023-10-09 10:27:22,987 [INFO] tensorflow: Done running local_init_op.\n",
      "112it [00:13,  8.13it/s]\n",
      "Recall : 0.7678544521331787\n",
      "\n",
      "Precision: 0.8905766904354095\n",
      "\n",
      "F1 score: 0.8150661924514047\n",
      "\n",
      "Mean IOU: 0.7180857360363007\n",
      "\n",
      "2023-10-09 10:27:35,338 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# evaluate the model using the same validation set as training\n",
    "!tao unet evaluate -e $TAO_SPECS_DIR/resnet18/combined_config.txt\\\n",
    "                   -m $TAO_EXPERIMENT_DIR/resnet18/weights/resnet18.tlt \\\n",
    "                   -o $TAO_EXPERIMENT_DIR/resnet18/ \\\n",
    "                   -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12815e-01d8-446d-bde2-28b82e3fc923",
   "metadata": {},
   "source": [
    "To understand how the TAO Toolkit measures accuracy of the segmentation model, we'll have to understand two measures: **recall** and **precision**. The first measure is focused on identifying positive cases and is called recall. We define recall as the ability of the model to identify all true positive samples of the dataset. In mathematical terms, recall is the ratio of true positives over true positives plus false negatives. By other means, recall tells us, among all the test samples belonging to the output class, how many of them are identified correctly by the model. The next measure is called precision and is defined as the ability of the model to identify the relevant samples only. It is the ratio of true positives over true positives plus false positives. A well-known measure that summarizes the balance between precision and recall is **f1-score**, which is their harmonic mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0319a-b49c-4dd8-94b2-795c30bed000",
   "metadata": {},
   "source": [
    "<a name='s2-2.8'></a>\n",
    "### Visualizing Model Inference ###\n",
    "The `inference` subtask for `unet` may be used to visualize segmentation and generate frame-by-frame PNG format labels on a directory of images. The labels will be generated in `mask_labels_tlt`. The tool also automatically generates segmentation overlayed images in `vis_overlay_tlt`. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d710380-3444-4947-ab09-e84711b94ed2",
   "metadata": {},
   "source": [
    "tao unet inference [-h] -e <EXPERIMENT_SPEC_FILE>\n",
    "                        -m <MODEL_PATH>\n",
    "                        -o <OUTPUT_DIR>\n",
    "                        -k <KEY>\n",
    "                        [--gpus GPUS]\n",
    "                        [--gpu_index GPU_INDEX]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7201565-fe89-4335-ae26-2e8c3f765950",
   "metadata": {},
   "source": [
    "When using the `inference` subtask, the `-e` argument indicates the path to the inference spec file, the `-m` argument indicates the path to the model file, the `-o` argument indicates the path to the output images directory, and the `-k` argument indicates the key to _load_ the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c38936aa-7709-405f-b655-6059f90670a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# remove any previous inference\n",
    "!rm -rf $LOCAL_PROJECT_DIR/tao_infer_testing/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623818b-9146-482a-97eb-1b76458c2f38",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 10:28:03,018 [INFO] root: Registry: ['nvcr.io']\n",
      "2023-10-09 10:28:03,158 [INFO] tlt.components.instance_handler.local_instance: Running command in container: nvcr.io/nvidia/tao/tao-toolkit-tf:v3.21.11-tf1.15.5-py3\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/scripts/inference.py:45: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/scripts/inference.py:45: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2023-10-09 10:28:07,978 [INFO] __main__: Loading experiment spec at /workspace/tao-experiments/spec_files/resnet18/combined_config.txt.\n",
      "2023-10-09 10:28:07,979 [INFO] iva.unet.spec_handler.spec_loader: Merging specification from /workspace/tao-experiments/spec_files/resnet18/combined_config.txt\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2023-10-09 10:28:07,980 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2023-10-09 10:28:07,993 [INFO] iva.unet.model.utilities: Label Id 0: Train Id 0\n",
      "2023-10-09 10:28:07,993 [INFO] iva.unet.model.utilities: Label Id 255: Train Id 1\n",
      "\n",
      "Phase test: Total 112 files.\n",
      "2023-10-09 10:28:08,010 [INFO] iva.unet.model.model_io: Loading weights from /workspace/tao-experiments/unet/resnet18/weights/resnet18.tlt\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/workspace/tao-experiments/unet/resnet18/weights', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fab2953ac18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "2023-10-09 10:28:11,937 [INFO] tensorflow: Using config: {'_model_dir': '/workspace/tao-experiments/unet/resnet18/weights', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fab2953ac18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "0it [00:00, ?it/s]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2023-10-09 10:28:12,281 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:28:12,316 [WARNING] tensorflow: Entity <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.read_image_and_label_tensors of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:28:12,327 [WARNING] tensorflow: Entity <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.rgb_to_bgr_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:28:12,332 [WARNING] tensorflow: Entity <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.cast_img_lbl_dtype_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:28:12,337 [WARNING] tensorflow: Entity <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.resize_image_and_label_tf of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/utils/data_loader.py:451: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "2023-10-09 10:28:12,338 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/unet/utils/data_loader.py:451: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <function Dataset.test_fn.<locals>.<lambda> at 0x7fab20a3df28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.test_fn.<locals>.<lambda> at 0x7fab20a3df28>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:28:12,344 [WARNING] tensorflow: Entity <function Dataset.test_fn.<locals>.<lambda> at 0x7fab20a3df28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.test_fn.<locals>.<lambda> at 0x7fab20a3df28>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <function Dataset.test_fn.<locals>.<lambda> at 0x7fab20a3d9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.test_fn.<locals>.<lambda> at 0x7fab20a3d9d8>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:28:12,352 [WARNING] tensorflow: Entity <function Dataset.test_fn.<locals>.<lambda> at 0x7fab20a3d9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <function Dataset.test_fn.<locals>.<lambda> at 0x7fab20a3d9d8>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:Entity <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2023-10-09 10:28:12,356 [WARNING] tensorflow: Entity <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Dataset.transpose_to_nchw of <iva.unet.utils.data_loader.Dataset object at 0x7fab29f8a780>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "2023-10-09 10:28:12,366 [INFO] tensorflow: Calling model_fn.\n",
      "2023-10-09 10:28:12,366 [INFO] iva.unet.utils.model_fn: {'exec_mode': 'train', 'model_dir': '/workspace/tao-experiments/unet/resnet18/weights', 'resize_padding': False, 'resize_method': 'BILINEAR', 'log_dir': None, 'batch_size': 1, 'learning_rate': 9.999999747378752e-05, 'activation': 'softmax', 'crossvalidation_idx': None, 'max_steps': None, 'regularizer_type': 2, 'weight_decay': 1.9999999494757503e-05, 'log_summary_steps': 10, 'warmup_steps': 0, 'augment': True, 'use_amp': False, 'use_trt': False, 'use_xla': False, 'loss': 'cross_dice_sum', 'epochs': 10, 'pretrained_weights_file': None, 'lr_scheduler': None, 'unet_model': <iva.unet.model.resnet_unet.ResnetUnet object at 0x7fab20553358>, 'key': 'my_model_key', 'experiment_spec': dataset_config {\n",
      "  augment: true\n",
      "  dataset: \"custom\"\n",
      "  input_image_type: \"color\"\n",
      "  train_images_path: \"/workspace/tao-experiments/data/images/train\"\n",
      "  train_masks_path: \"/workspace/tao-experiments/data/masks/train\"\n",
      "  val_images_path: \"/workspace/tao-experiments/data/images/val\"\n",
      "  val_masks_path: \"/workspace/tao-experiments/data/masks/val\"\n",
      "  test_images_path: \"/workspace/tao-experiments/data/images/val\"\n",
      "  data_class_config {\n",
      "    target_classes {\n",
      "      name: \"notflood\"\n",
      "      mapping_class: \"notflood\"\n",
      "    }\n",
      "    target_classes {\n",
      "      name: \"flood\"\n",
      "      label_id: 255\n",
      "      mapping_class: \"flood\"\n",
      "    }\n",
      "  }\n",
      "  augmentation_config {\n",
      "    spatial_augmentation {\n",
      "      hflip_probability: 0.5\n",
      "      vflip_probability: 0.5\n",
      "      crop_and_resize_prob: 0.5\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_config {\n",
      "  num_layers: 18\n",
      "  use_batch_norm: true\n",
      "  training_precision {\n",
      "    backend_floatx: FLOAT32\n",
      "  }\n",
      "  arch: \"resnet\"\n",
      "  all_projections: true\n",
      "  model_input_height: 512\n",
      "  model_input_width: 512\n",
      "  model_input_channels: 3\n",
      "}\n",
      "training_config {\n",
      "  batch_size: 1\n",
      "  regularizer {\n",
      "    type: L2\n",
      "    weight: 1.9999999494757503e-05\n",
      "  }\n",
      "  optimizer {\n",
      "    adam {\n",
      "      epsilon: 9.99999993922529e-09\n",
      "      beta1: 0.8999999761581421\n",
      "      beta2: 0.9990000128746033\n",
      "    }\n",
      "  }\n",
      "  checkpoint_interval: 10\n",
      "  log_summary_steps: 10\n",
      "  learning_rate: 9.999999747378752e-05\n",
      "  loss: \"cross_dice_sum\"\n",
      "  epochs: 10\n",
      "}\n",
      ", 'seed': 0, 'benchmark': False, 'temp_dir': '/tmp/tmpshsigjz3', 'num_classes': 2, 'num_conf_mat_classes': 2, 'start_step': 0, 'checkpoint_interval': 10, 'model_json': None, 'load_graph': False, 'weights_monitor': False, 'phase': 'test'}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2023-10-09 10:28:12,367 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2023-10-09 10:28:12,367 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2023-10-09 10:28:12,381 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2023-10-09 10:28:12,384 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 512, 512)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 256, 256) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 256, 256) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 256, 256) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 128, 128) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 128, 128) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 128, 128) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 128, 128) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 128, 128) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 128, 128) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 128, 128) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 128, 128) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 128, 128) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 128, 128) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 128, 128) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 128, 128) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 128, 128) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 128, 128) 4160        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 128, 128) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 128, 128) 256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 128, 128) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 128, 128) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 64, 64)  73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 64, 64)  512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 64, 64)  0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 64, 64)  147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 64, 64)  8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 64, 64)  512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 64, 64)  512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 64, 64)  0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 64, 64)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 64, 64)  147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 64, 64)  512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 64, 64)  0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 64, 64)  147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 64, 64)  16512       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 64, 64)  512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 64, 64)  512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 64, 64)  0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 64, 64)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 32, 32)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 32, 32)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 32, 32)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 32, 32)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 32, 32)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 32, 32)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 32, 32)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 32, 32)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 32, 32)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 32, 32)  590080      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 32, 32)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 32, 32)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 32, 32)  590080      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 32, 32)  65792       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 32, 32)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 32, 32)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 32, 32)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 32, 32)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 32, 32)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 32, 32)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 32, 32)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 32, 32)  2359808     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 32, 32)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 32, 32)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 32, 32)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 32, 32)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 32, 32)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 32, 32)  2359808     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 32, 32)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 32, 32)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 32, 32)  2359808     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_shortcut (Conv2D) (None, 512, 32, 32)  262656      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 32, 32)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_shortcut (BatchNorm (None, 512, 32, 32)  2048        block_4b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 32, 32)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 32, 32)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 64, 64)  2097408     block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384, 64, 64)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 384, 64, 64)  1536        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 384, 64, 64)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 64, 64)  884992      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 64, 64)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 64, 64)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 524416      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192, 128, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 192, 128, 128 768         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 192, 128, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 221312      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 256, 256) 131136      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 256, 256 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 256, 256 512         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 256, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 256, 256) 73792       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 256, 256) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 256, 256) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 512, 512) 65600       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 512, 512) 256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 512, 512) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 512, 512) 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 512, 512) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 512, 512) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 2, 512, 512)  1154        activation_9[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 15,590,146\n",
      "Trainable params: 15,575,938\n",
      "Non-trainable params: 14,208\n",
      "__________________________________________________________________________________________________\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "2023-10-09 10:28:13,805 [INFO] tensorflow: Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2023-10-09 10:28:14,062 [INFO] tensorflow: Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpvjxh4it9/model.ckpt-3340\n",
      "2023-10-09 10:28:14,439 [INFO] tensorflow: Restoring parameters from /tmp/tmpvjxh4it9/model.ckpt-3340\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "2023-10-09 10:28:14,814 [INFO] tensorflow: Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "2023-10-09 10:28:14,857 [INFO] tensorflow: Done running local_init_op.\n",
      "112it [00:15,  7.18it/s]\n",
      "2023-10-09 10:28:29,021 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# perform inference on the validation set\n",
    "!tao unet inference -e $TAO_SPECS_DIR/resnet18/combined_config.txt \\\n",
    "                    -m $TAO_EXPERIMENT_DIR/resnet18/weights/resnet18.tlt \\\n",
    "                    -o $TAO_PROJECT_DIR/tao_infer_testing \\\n",
    "                    -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b47fee3-fb55-4f1b-895d-9a2343061ffc",
   "metadata": {},
   "source": [
    "We can write a quick function that will help us sample random inferences. Execute the below cells to visualize the inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f4432-7f6b-4f08-be88-5c7eee82e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# define simple grid visualizer\n",
    "def visualize_images(num_images=10):\n",
    "    overlay_path=os.path.join(os.environ['LOCAL_PROJECT_DIR'], 'tao_infer_testing', 'vis_overlay_tlt')\n",
    "    inference_path=os.path.join(os.environ['LOCAL_PROJECT_DIR'], 'tao_infer_testing', 'mask_labels_tlt')\n",
    "    actual_path=os.path.join(os.environ['LOCAL_DATA_DIR'], 'masks', 'val')\n",
    "    inference_images_path=os.path.join(os.environ['LOCAL_DATA_DIR'], 'images', 'val')\n",
    "        \n",
    "    fig_dim=4\n",
    "    fig, ax_arr=plt.subplots(num_images, 4, figsize=[4*fig_dim, num_images*fig_dim], sharex=True, sharey=True)\n",
    "    ax_arr[0, 0].set_title('Overlay')\n",
    "    ax_arr[0, 1].set_title('Input')\n",
    "    ax_arr[0, 2].set_title('Inference')\n",
    "    ax_arr[0, 3].set_title('Actual')\n",
    "    ax_arr[0, 0].set_xticks([])\n",
    "    ax_arr[0, 0].set_yticks([])\n",
    "    \n",
    "    for idx, img_name in enumerate(random.sample(os.listdir(actual_path), num_images)):\n",
    "        ax_arr[idx, 0].imshow(plt.imread(overlay_path+'/'+img_name))\n",
    "        ax_arr[idx, 0].set_ylabel(img_name)\n",
    "        ax_arr[idx, 1].imshow(plt.imread(inference_images_path+'/'+img_name))\n",
    "        ax_arr[idx, 2].imshow(plt.imread(inference_path+'/'+img_name), cmap='gray')\n",
    "        ax_arr[idx, 3].imshow(plt.imread(actual_path+'/'+img_name), cmap='gray')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340185d-c1c8-4051-8998-222f1b9b102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# visualizing random images\n",
    "NUM_IMAGES = 4\n",
    "\n",
    "visualize_images(NUM_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdbad0-41a0-4fd7-b09f-6d8dabf5c9fc",
   "metadata": {},
   "source": [
    "<a name='s2-3'></a>\n",
    "## Model Export ##\n",
    "Once we are satisfied with our model, we can move to deployment. `unet` includes an `export` subtask to export and prepare a trained U-Net model for deployment. Exporting the model decouples the training process from deployment and allows conversion to TensorRT engines outside the TAO environment. TensorRT is a highly optimized package that takes trained models and optimizes them for inference. TensorRT engines are specific to each hardware configuration and should be generated for each unique inference environment. This may be interchangeably referred to as the `.trt` or `.engine` file. The same exported TAO model may be used universally across training and deployment hardware. This is referred to as the `.etlt` file, or encrypted TAO file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8639a37-72d6-4e0f-95f4-d3de568f03a0",
   "metadata": {},
   "source": [
    "<a name='s2-3.1'></a>\n",
    "### TensorRT - Programmable Inference Accelerator\n",
    "\n",
    "NVIDIA [TensorRT](https://developer.nvidia.com/tensorrt) is a platform for high-performance deep learning inference. It includes a deep learning inference optimizer and runtime that delivers low latency and high throughput for deep learning inference applications. TensorRT-based applications perform up to 40x faster than CPU-only platforms during inference. \n",
    "\n",
    "With TensorRT, we can optimize neural network models trained in all major frameworks, calibrate for lower precision with high accuracy, and finally deploy to hyperscale data centers, embedded, or automotive product platforms.\n",
    "\n",
    "How TensorRT enables optimizations on the layer graph: \n",
    "* Elimination of layers whose outputs are not used\n",
    "* Fusion of convolution, bias, and ReLU operations\n",
    "* Aggregation of operations with sufficiently similar parameters and the same source tensor (for example, the 1x1 convolutions in GoogleNet’ s inception module)\n",
    "* Merging of concatenation layers by directing layer outputs to the correct eventual destination\n",
    "\n",
    "Here are some great resources to learn more about TensorRT:\n",
    " \n",
    "* Main Page: https://developer.nvidia.com/tensorrt\n",
    "* Blogs: https://devblogs.nvidia.com/speed-up-inference-tensorrt/\n",
    "* Download: https://developer.nvidia.com/nvidia-tensorrt-download\n",
    "* Documentation: https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html\n",
    "* Sample Code: https://docs.nvidia.com/deeplearning/sdk/tensorrt-sample-support-guide/index.html\n",
    "* GitHub: https://github.com/NVIDIA/TensorRT\n",
    "* NGC Container: https://ngc.nvidia.com/catalog/containers/nvidia:tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1cd365-e7fd-4c8c-b03e-9d8c310b0e08",
   "metadata": {},
   "source": [
    "<a name='s2-3.2'></a>\n",
    "### Export the Trained Model ###\n",
    "When using the `export` subtask, the `-m` argument indicates the path to the `.tlt` model file to be exported, the `-e` argument indicates the path to the spec file, and `-k` argument indicates the key to _load_ the model. There are two optional arguments, `--gen_ds_config` and `--engine_file` that are useful for us. The `--gen_ds_config` argument indicates whether to generate a template inference configuration file as well as a label file. The `--engine_file` indicates the path to the serialized TensorRT engine file. \n",
    "<p><img src='images/important.png' width=720></p>\n",
    "\n",
    "Note that the TensorRT file is hardware specific and cannot be generalized across GPUs. Since a TensorRT engine file is hardware specific, you cannot use an engine file for deployment unless the deployment GPU is identical to the training GPU. This is true in our case since the Triton Inference Server will run on the same hardware. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "afb18b3b-86a5-4c4f-9296-a310516a8c8f",
   "metadata": {},
   "source": [
    "tao unet export [-h] -e <EXPERIMENT_SPEC>\n",
    "                     -m <MODEL>\n",
    "                     -k <KEY>\n",
    "                     [--engine_file ENGINE_FILE]\n",
    "                     [--gen_ds_config]\n",
    "                     [--gpus GPUS]\n",
    "                     [--gpu_index GPU_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcae38a-6f81-4818-b428-bd653e208680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# remove any previous exports if exists\n",
    "!rm $LOCAL_EXPERIMENT_DIR/resnet18/weights/resnet18.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae7c99c-2576-499e-8b37-347a1c20d4a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# export model and TensorRT engine\n",
    "!tao unet export -m $TAO_EXPERIMENT_DIR/resnet18/weights/resnet18.tlt \\\n",
    "                 -e $TAO_SPECS_DIR/resnet18/combined_config.txt \\\n",
    "                 -k $KEY \\\n",
    "                 --engine_file $TAO_EXPERIMENT_DIR/export/resnet18.engine \\\n",
    "                 --gen_ds_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01280ca6-e986-4fe6-9ec5-366e8cf6df8a",
   "metadata": {},
   "source": [
    "**Well Done!** Let's move to the [next notebook](./03_model_deployment_for_inference.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e715988-e892-4565-bcb9-85c289eefd2d",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/combined_logo.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
